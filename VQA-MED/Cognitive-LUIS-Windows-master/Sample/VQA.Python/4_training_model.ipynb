{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180629_1514_58\\\\vqa_model_NLP.h5'\n",
    "strategy_str = 'NLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas import HDFStore\n",
    "from vqa_logger import logger \n",
    "from enum import Enum\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.constatns import data_location, vqa_models_folder #train_data, validation_data, \n",
    "from common.utils import VerboseTimer\n",
    "from common.settings import classify_strategy\n",
    "from common.classes import ClassifyStrategies\n",
    "from common.model_utils import save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: 0:00:02.997215\n"
     ]
    }
   ],
   "source": [
    "with VerboseTimer(\"Loading Model\"):\n",
    "    model = load_model(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:32][DEBUG] Loading the data from C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\Cognitive-LUIS-Windows-master\\Sample\\VQA.Python\\data\\model_input.h5\n",
      "Loading Data: 0:00:16.858264\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"Loading the data from {data_location}\")\n",
    "with VerboseTimer(\"Loading Data\"):\n",
    "    with HDFStore(data_location) as store:\n",
    "        df_data = store['data']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:49][DEBUG] df_data Shape: (5913, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>group</th>\n",
       "      <th>path</th>\n",
       "      <th>question_embedding</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rjv03401.jpg</td>\n",
       "      <td>what does mri show?</td>\n",
       "      <td>lesion at tail of pancreas</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>[[-1.8407480716705322, 2.5507988929748535, 0.7...</td>\n",
       "      <td>[[2.7199699878692627, 0.11310356855392456, -0....</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAN-14-313-g002.jpg</td>\n",
       "      <td>where does axial section mri abdomen show hypo...</td>\n",
       "      <td>in distal pancreas</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>[[0.35850387811660767, 1.4076576232910156, -3....</td>\n",
       "      <td>[[1.1828632354736328, 0.4119483232498169, -3.4...</td>\n",
       "      <td>[[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_name                                           question  \\\n",
       "0          rjv03401.jpg                                what does mri show?   \n",
       "1  AIAN-14-313-g002.jpg  where does axial section mri abdomen show hypo...   \n",
       "\n",
       "                       answer  group  \\\n",
       "0  lesion at tail of pancreas  train   \n",
       "1          in distal pancreas  train   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...   \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...   \n",
       "\n",
       "                                  question_embedding  \\\n",
       "0  [[-1.8407480716705322, 2.5507988929748535, 0.7...   \n",
       "1  [[0.35850387811660767, 1.4076576232910156, -3....   \n",
       "\n",
       "                                    answer_embedding  \\\n",
       "0  [[2.7199699878692627, 0.11310356855392456, -0....   \n",
       "1  [[1.1828632354736328, 0.4119483232498169, -3.4...   \n",
       "\n",
       "                                               image  \n",
       "0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "1  [[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.debug(f\"df_data Shape: {df_data.shape}\")\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packaging the data to be in expected input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_data[df_data.group == 'train']\n",
    "data_val = df_data[df_data.group == 'validation']\n",
    "\n",
    "\n",
    "# print(f'groups:\\n{df_data.group.drop_duplicates()}')\n",
    "# print(len(df_data))\n",
    "# data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:56][DEBUG] Getting train features\n",
      "[23:33:58][DEBUG] Getting validation features\n"
     ]
    }
   ],
   "source": [
    "def concate_row(df, col):\n",
    "    return np.concatenate(df[col], axis=0)\n",
    "\n",
    "def get_features_and_labels(df):\n",
    "    image_features = np.asarray([np.array(im) for im in df['image']])\n",
    "    # np.concatenate(image_features['question_embedding'], axis=0).shape\n",
    "    question_features = concate_row(df, 'question_embedding') \n",
    "\n",
    "    features = ([f for f in [question_features, image_features]])\n",
    "    labels =  concate_row(df, 'answer_embedding')\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "logger.debug('Getting train features')\n",
    "features_t, labels_t = get_features_and_labels(data_train)\n",
    "logger.debug('Getting validation features')\n",
    "features_val, labels_val = get_features_and_labels(data_val)\n",
    "\n",
    "# Note: The shape of answer (for a single recored ) is (number of words, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attempt for using categorial classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5413"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if classify_strategy == ClassifyStrategies.CATEGORIAL:\n",
    "    labels_t = categorial_labels_train\n",
    "    labels_val = categorial_labels_val    \n",
    "elif classify_strategy == ClassifyStrategies.NLP:\n",
    "    pass\n",
    "else:\n",
    "    raise Exception(f'Unfamilier strategy: {strat}')\n",
    "classify_strategy\n",
    "\n",
    "len(features_t[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = (features_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectedt shape: [(None, 12288), (None, None, None, 3)]\n",
      "---------------------------------------------------------------------------\n",
      "Actual training shape:((5413, 12288), (5413, 224, 224, 3))\n",
      "Train Labels shape:(5413, 12288)\n",
      "---------------------------------------------------------------------------\n",
      "Actual Validation shape:((500, 12288), (500, 224, 224, 3))\n",
      "Validation Labels shape:(500, 12288)\n"
     ]
    }
   ],
   "source": [
    "# model.input_layers\n",
    "# model.input_layers_node_indices\n",
    "# model.input_layers_tensor_indices\n",
    "# model.input_mask\n",
    "# model.input_names\n",
    "\n",
    "\n",
    "# model.inputs\n",
    "# model.input\n",
    "# model.input_spec\n",
    "\n",
    "# print(f'Wrapper shape:{train_features.shape}')\n",
    "# model.input_shape, np.concatenate(train_features).shape\n",
    "# model.input_shape, train_features[0].shape,  train_features[1].shape\n",
    "\n",
    "print(f'Expectedt shape: {model.input_shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual training shape:{features_t[0].shape, features_t[1].shape}')\n",
    "print(f'Train Labels shape:{labels_t.shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual Validation shape:{features_val[0].shape, features_val[1].shape}')\n",
    "print(f'Validation Labels shape:{labels_val.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5413 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "5413/5413 [==============================] - 108s 20ms/step - loss: -3552.5714 - acc: 0.0345 - val_loss: -2538.6444 - val_acc: 0.0280\n",
      "Epoch 2/25\n",
      "5413/5413 [==============================] - 103s 19ms/step - loss: -4023.7848 - acc: 0.0364 - val_loss: -2783.2791 - val_acc: 0.0260\n",
      "Epoch 3/25\n",
      " 820/5413 [===>..........................] - ETA: 1:20 - loss: -4109.2849 - acc: 0.0402"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "EPOCHS=25\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# train_features = image_name_question\n",
    "# validation_input = (validation_features, categorial_validation_labels)\n",
    "\n",
    "## construct the image generator for data augmentation\n",
    "# aug = image.ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "#                                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "#                                horizontal_flip=True, fill_mode=\"nearest\")\n",
    "# train_generator = aug.flow(train_features, categorial_train_labels)\n",
    "\n",
    "# stop_callback = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1,mode='auto')\n",
    "\n",
    "try:\n",
    "#     history = model.fit_generator(train_generator,\n",
    "#                                   validation_data=validation_input,\n",
    "#                                   steps_per_epoch=len(train_features) // self.batch_size,\n",
    "#                                   epochs=self.epochs,\n",
    "#                                   verbose=1,\n",
    "#                                   callbacks=[stop_callback],\n",
    "#                                   class_weight=class_weight\n",
    "#                                   )\n",
    "    # verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    with VerboseTimer(\"Training Model\"):\n",
    "        history = model.fit(features_t,labels_t,\n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data=validation_input)\n",
    "except Exception as ex:\n",
    "    logger.error(\"Got an error training model: {0}\".format(ex))\n",
    "#     model.summary(print_fn=logger.error)\n",
    "    raise\n",
    "# return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with VerboseTimer(\"Saving trained Model\"):\n",
    "    name_suffix = f'{classify_strategy}_trained'\n",
    "    model_fn, summary_fn, fn_image = save_model(model, vqa_models_folder, name_suffix=name_suffix)\n",
    "\n",
    "msg = f\"Summary: {summary_fn}\\n\"\n",
    "msg += f\"Image: {fn_image}\\n\"\n",
    "location_message = f\"model_location = '{model_fn}'\"\n",
    "\n",
    "\n",
    "print(msg)\n",
    "print(location_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (location_message.replace('\\\\','\\\\\\\\'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_env",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
