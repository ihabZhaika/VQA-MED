{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180627_2043_32\\\\vqa_model_NLP.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas import HDFStore\n",
    "from vqa_logger import logger \n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Duplicate:\n",
    "data_location      = os.path.abspath('./data/model_input.h5')\n",
    "\n",
    "\n",
    "class ClassifyStrategies(Enum):\n",
    "    NLP = 1\n",
    "    CATEGORIAL = 2\n",
    "    \n",
    "# classify_strategy = ClassifyStrategies.CATEGORIAL\n",
    "classify_strategy = ClassifyStrategies.NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:08][DEBUG] Load the data\n",
      "[20:47:41][DEBUG] Shape: (5413, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>path</th>\n",
       "      <th>question_embedding</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rjv03401.jpg</td>\n",
       "      <td>what does mri show?</td>\n",
       "      <td>lesion at tail of pancreas</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>[[-1.8407480716705322, 2.5507988929748535, 0.7...</td>\n",
       "      <td>[[2.7199699878692627, 0.11310356855392456, -0....</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAN-14-313-g002.jpg</td>\n",
       "      <td>where does axial section mri abdomen show hypo...</td>\n",
       "      <td>in distal pancreas</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>[[0.35850387811660767, 1.4076576232910156, -3....</td>\n",
       "      <td>[[1.1828632354736328, 0.4119483232498169, -3.4...</td>\n",
       "      <td>[[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_name                                           question  \\\n",
       "0          rjv03401.jpg                                what does mri show?   \n",
       "1  AIAN-14-313-g002.jpg  where does axial section mri abdomen show hypo...   \n",
       "\n",
       "                       answer  \\\n",
       "0  lesion at tail of pancreas   \n",
       "1          in distal pancreas   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...   \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...   \n",
       "\n",
       "                                  question_embedding  \\\n",
       "0  [[-1.8407480716705322, 2.5507988929748535, 0.7...   \n",
       "1  [[0.35850387811660767, 1.4076576232910156, -3....   \n",
       "\n",
       "                                    answer_embedding  \\\n",
       "0  [[2.7199699878692627, 0.11310356855392456, -0....   \n",
       "1  [[1.1828632354736328, 0.4119483232498169, -3.4...   \n",
       "\n",
       "                                               image  \n",
       "0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "1  [[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.debug(\"Load the data\")\n",
    "with HDFStore(data_location) as store:\n",
    "    image_name_question = store['train']  \n",
    "    image_name_question_val = store['val']  \n",
    "\n",
    "\n",
    "logger.debug(f\"Shape: {image_name_question.shape}\")\n",
    "image_name_question.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packaging the data to be in expected input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concate_row(df, col):\n",
    "    return np.concatenate(df[col], axis=0)\n",
    "\n",
    "def get_features_and_labels(df):\n",
    "    image_features = np.asarray([np.array(im) for im in df['image']])\n",
    "    # np.concatenate(image_features['question_embedding'], axis=0).shape\n",
    "    question_features = concate_row(df, 'question_embedding') \n",
    "\n",
    "    features = ([f for f in [question_features, image_features]])\n",
    "    labels =  concate_row(df, 'answer_embedding')\n",
    "    return features, labels\n",
    "\n",
    "features_t, labels_t = get_features_and_labels(image_name_question)\n",
    "features_val, labels_val = get_features_and_labels(image_name_question_val)\n",
    "\n",
    "# Note: The shape of answer (for a single recored ) is (number of words, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attempt for using categorial classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5413"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if classify_strategy == ClassifyStrategies.CATEGORIAL:\n",
    "    labels_t = categorial_labels_train\n",
    "    labels_val = categorial_labels_val    \n",
    "elif classify_strategy == ClassifyStrategies.NLP:\n",
    "    pass\n",
    "else:\n",
    "    raise Exception(f'Unfamilier strategy: {strat}')\n",
    "classify_strategy\n",
    "\n",
    "len(features_t[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = (features_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectedt shape: [(None, 12288), (None, None, None, 3)]\n",
      "---------------------------------------------------------------------------\n",
      "Actual training shape:((5413, 12288), (5413, 224, 224, 3))\n",
      "Train Labels shape:(5413, 12288)\n",
      "---------------------------------------------------------------------------\n",
      "Actual Validation shape:((500, 12288), (500, 224, 224, 3))\n",
      "Validation Labels shape:(500, 12288)\n"
     ]
    }
   ],
   "source": [
    "# model.input_layers\n",
    "# model.input_layers_node_indices\n",
    "# model.input_layers_tensor_indices\n",
    "# model.input_mask\n",
    "# model.input_names\n",
    "\n",
    "\n",
    "# model.inputs\n",
    "# model.input\n",
    "# model.input_spec\n",
    "\n",
    "# print(f'Wrapper shape:{train_features.shape}')\n",
    "# model.input_shape, np.concatenate(train_features).shape\n",
    "# model.input_shape, train_features[0].shape,  train_features[1].shape\n",
    "\n",
    "print(f'Expectedt shape: {model.input_shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual training shape:{features_t[0].shape, features_t[1].shape}')\n",
    "print(f'Train Labels shape:{labels_t.shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual Validation shape:{features_val[0].shape, features_val[1].shape}')\n",
    "print(f'Validation Labels shape:{labels_val.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5413 samples, validate on 500 samples\n",
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "EPOCHS=25\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# train_features = image_name_question\n",
    "# validation_input = (validation_features, categorial_validation_labels)\n",
    "\n",
    "## construct the image generator for data augmentation\n",
    "# aug = image.ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "#                                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "#                                horizontal_flip=True, fill_mode=\"nearest\")\n",
    "# train_generator = aug.flow(train_features, categorial_train_labels)\n",
    "\n",
    "# stop_callback = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1,mode='auto')\n",
    "\n",
    "try:\n",
    "#     history = model.fit_generator(train_generator,\n",
    "#                                   validation_data=validation_input,\n",
    "#                                   steps_per_epoch=len(train_features) // self.batch_size,\n",
    "#                                   epochs=self.epochs,\n",
    "#                                   verbose=1,\n",
    "#                                   callbacks=[stop_callback],\n",
    "#                                   class_weight=class_weight\n",
    "#                                   )\n",
    "    # verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "    history = model.fit(features_t,labels_t,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=validation_input)\n",
    "except Exception as ex:\n",
    "    logger.error(\"Got an error training model: {0}\".format(ex))\n",
    "#     model.summary(print_fn=logger.error)\n",
    "    raise\n",
    "# return model, history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_env",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
