{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQA - MED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the efforts made for Visual Q&A based on the data set from VQA-Med 2018 contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs for VQA are:\n",
    "1. The question text \n",
    "2. The image\n",
    "\n",
    "The question text is being embedded into a feature vector using a pre-traing [globe file](https://nlp.stanford.edu/projects/glove/). \n",
    "\n",
    "In a similar manner the image is being processed using a pre trained deep NN (e.g. [VGG](http://qr.ae/TUTEKo) with initial wights of a pretrained [imagenet model](https://en.wikipedia.org/wiki/ImageNet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. [Preperations and helpers](#Preperations-and-helpers)\n",
    "1. [Collecting pre processing item](#Collecting-pre-processing-item)\n",
    "2. [Preprocessing and creating meta data](#Preprocessing-and-creating-meta-data)\n",
    "3. [Creating the model](#Creating-the-model)\n",
    "4. [Training the model](#Training-the-model)\n",
    "5. [Testing the model](#Testing-the-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperations and helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are just helpers & utils imports - feel free to skip..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parsers.utils import VerboseTimer\n",
    "from utils.os_utils import File, print_progress\n",
    "import time, datetime\n",
    "\n",
    "def get_time_stamp():\n",
    "    now = time.time()\n",
    "    ts = datetime.datetime.fromtimestamp(now).strftime('%Y%m%d_%H%M_%S')\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting pre processing item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Download pre trained items & store their location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Add down loading for glove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "seq_length =    26\n",
    "embedding_dim = 300\n",
    "\n",
    "glove_path =                    os.path.abspath('data/glove.6B.{0}d.txt'.format(embedding_dim))\n",
    "embedding_matrix_filename =     os.path.abspath('data/ckpts/embeddings_{0}.h5'.format(embedding_dim))\n",
    "ckpt_model_weights_filename =   os.path.abspath('data/ckpts/model_weights.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_IMAGE_WIEGHTS = 'imagenet'\n",
    "#  Since VGG was trained as a image of 224x224, every new image\n",
    "# is required to go through the same transformation\n",
    "image_size_by_base_models = {'imagenet': (224, 224)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated file locations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Fail fast...\n",
    "suffix = \"Failing fast:\\n\"\n",
    "assert os.path.isfile(glove_path), suffix+\"glove file does not exists:\\n{0}\".format(glove_path)\n",
    "# assert os.path.isfile(embedding_matrix_filename), suffix+\"Embedding matrix file does not exist:\\n{0}\".format(embedding_matrix_filename)\n",
    "assert os.path.isfile(ckpt_model_weights_filename), suffix+\"glove file does not exists:\\n{0}\".format(ckpt_model_weights_filename)\n",
    "\n",
    "print('Validated file locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set locations for pre-training items to-be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre process results files\n",
    "data_prepo_meta            = os.path.abspath('data/my_data_prepro.json')\n",
    "data_prepo_meta_validation = os.path.abspath('data/my_data_prepro_validation.json')\n",
    "# Location of embediing pre trained matrix\n",
    "embedding_matrix_filename  = os.path.abspath('data/ckpts/embeddings_{0}.h5'.format(embedding_dim))\n",
    "\n",
    "# The location to dump models to\n",
    "vqa_models_folder          = \"C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and creating meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function for creating meta data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vqa_logger import logger \n",
    "import itertools\n",
    "import string\n",
    "from utils.os_utils import File #This is a simplehelper file of mine...\n",
    "\n",
    "def create_meta(meta_file_location, df):\n",
    "        logger.debug(\"Creating meta data ('{0}')\".format(meta_file_location))\n",
    "        def get_unique_words(col):\n",
    "            single_string = \" \".join(df[col])\n",
    "            exclude = set(string.punctuation)\n",
    "            s_no_panctuation = ''.join(ch for ch in single_string if ch not in exclude)\n",
    "            unique_words = set(s_no_panctuation.split(\" \")).difference({'',' '})\n",
    "            print(\"column {0} had {1} unique words\".format(col,len(unique_words)))\n",
    "            return unique_words\n",
    "\n",
    "        cols = ['question', 'answer']\n",
    "        unique_words = set(itertools.chain.from_iterable([get_unique_words(col) for col in cols]))\n",
    "        print(\"total unique words: {0}\".format(len(unique_words)))\n",
    "\n",
    "        metadata = {}\n",
    "        metadata['ix_to_word'] = {str(word): int(i) for i, word in enumerate(unique_words)}\n",
    "        metadata['ix_to_ans'] = {ans:i for ans, i in enumerate(set(df['answer']))}\n",
    "        # {int(i):str(word) for i, word in enumerate(unique_words)}\n",
    "\n",
    "        File.dump_json(metadata,meta_file_location)\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets create meta data for training & validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "dbg_file_csv_train = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Train\\\\VQAMed2018Train-QA.csv'\n",
    "dbg_file_xls_train = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Train\\\\VQAMed2018Train-QA_post_pre_process_intermediate.xlsx'#\"'C:\\\\\\\\Users\\\\\\\\avitu\\\\\\\\Documents\\\\\\\\GitHub\\\\\\\\VQA-MED\\\\\\\\VQA-MED\\\\\\\\Cognitive-LUIS-Windows-master\\\\\\\\Sample\\\\\\\\VQA.Python\\\\\\\\dumped_data\\\\\\\\vqa_data.xlsx'\n",
    "dbg_file_xls_processed_train = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Train\\\\VQAMed2018Train-QA_post_pre_process.xlsx'\n",
    "train_embedding_path = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Train\\\\VQAMed2018Train-images\\\\embbeded_images.hdf'\n",
    "images_path_train = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Train\\\\VQAMed2018Train-images'\n",
    "\n",
    "\n",
    "dbg_file_csv_validation = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Valid\\\\VQAMed2018Valid-QA.csv'\n",
    "dbg_file_xls_validation = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Valid\\\\VQAMed2018Valid-QA_post_pre_process_intermediate.xlsx'\n",
    "dbg_file_xls_processed_validation = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Valid\\\\VQAMed2018Valid-QA_post_pre_process.xlsx'\n",
    "validation_embedding_path = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Valid\\\\VQAMed2018Valid-images\\\\embbeded_images.hdf'\n",
    "images_path_validation = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Valid\\\\VQAMed2018Valid-images'\n",
    "\n",
    "\n",
    "dbg_file_csv_test = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Test\\\\VQAMed2018Test-QA.csv'\n",
    "dbg_file_xls_test = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Test\\\\VQAMed2018Test-QA_post_pre_process_intermediate.xlsx'\n",
    "dbg_file_xls_processed_test = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Test\\\\VQAMed2018Test-QA_post_pre_process.xlsx'\n",
    "test_embedding_path = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Test\\\\VQAMed2018Test-images\\\\embbeded_images.hdf'\n",
    "images_path_test = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\VQAMed2018Test\\\\VQAMed2018Test-images'\n",
    "\n",
    "DataLocations = namedtuple('DataLocations', ['data_tag', 'raw_csv', 'raw_xls', 'processed_xls','images_path'])\n",
    "train_data = DataLocations('train', dbg_file_csv_train,dbg_file_xls_train,dbg_file_xls_processed_train, images_path_train)\n",
    "validation_data = DataLocations('validation', dbg_file_csv_validation, dbg_file_xls_validation, dbg_file_xls_processed_validation, images_path_validation)\n",
    "test_data = DataLocations('test', dbg_file_csv_test, dbg_file_xls_test, dbg_file_xls_processed_test, images_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data itself, Note the only things required in dataframe are:\n",
    "1. image_name\n",
    "2. question\n",
    "3. answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:07:52,368 matplotlib DEBUG ## $HOME=C:\\Users\\avitu\n",
      "09:07:52,370 matplotlib DEBUG ## matplotlib data path c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\matplotlib\\mpl-data\n",
      "09:07:52,376 matplotlib DEBUG ## loaded rc file c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\matplotlib\\mpl-data\\matplotlibrc\n",
      "09:07:52,378 matplotlib DEBUG ## matplotlib version 2.2.2\n",
      "09:07:52,379 matplotlib DEBUG ## interactive is False\n",
      "09:07:52,380 matplotlib DEBUG ## platform is win32\n",
      "09:07:52,381 matplotlib DEBUG ## loaded modules: ['builtins', 'sys', '_frozen_importlib', '_imp', '_warnings', '_thread', '_weakref', '_frozen_importlib_external', '_io', 'marshal', 'nt', 'winreg', 'zipimport', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_weakrefset', '_bootlocale', '_locale', 'encodings.cp1255', 'site', 'os', 'errno', 'stat', '_stat', 'ntpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', 'sysconfig', 'types', 'functools', '_functools', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'weakref', 'collections.abc', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'mpl_toolkits', 'google', 'runpy', 'pkgutil', 'ipykernel', 'ipykernel._version', 'ipykernel.connect', '__future__', 'json', 'json.decoder', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'json.scanner', '_json', 'json.encoder', 'subprocess', 'time', 'signal', 'threading', 'traceback', 'linecache', 'tokenize', 'token', 'msvcrt', '_winapi', 'IPython', 'IPython.core', 'IPython.core.getipython', 'IPython.core.release', 'IPython.core.application', 'atexit', 'copy', 'glob', 'fnmatch', 'posixpath', 'logging', 'string', '_string', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'traitlets', 'traitlets.traitlets', 'inspect', 'ast', '_ast', 'dis', 'opcode', '_opcode', 'six', 'struct', '_struct', 'traitlets.utils', 'traitlets.utils.getargspec', 'traitlets.utils.importstring', 'ipython_genutils', 'ipython_genutils._version', 'ipython_genutils.py3compat', 'ipython_genutils.encoding', 'locale', 'platform', 'traitlets.utils.sentinel', 'traitlets.utils.bunch', 'traitlets._version', 'traitlets.config', 'traitlets.config.application', 'decorator', 'traitlets.config.configurable', 'traitlets.config.loader', 'argparse', 'textwrap', 'gettext', 'ipython_genutils.path', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'ipython_genutils.text', 'ipython_genutils.importstring', 'IPython.core.crashhandler', 'pprint', 'IPython.core.ultratb', 'pydoc', 'urllib', 'urllib.parse', 'IPython.core.debugger', 'bdb', 'IPython.utils', 'IPython.utils.PyColorize', 'IPython.utils.coloransi', 'IPython.utils.ipstruct', 'IPython.utils.colorable', 'pygments', 'pygments.util', 'IPython.utils.py3compat', 'IPython.utils.encoding', 'IPython.core.excolors', 'IPython.testing', 'IPython.testing.skipdoctest', 'pdb', 'cmd', 'code', 'codeop', 'IPython.core.display_trap', 'IPython.utils.openpy', 'IPython.utils.path', 'IPython.utils.process', 'IPython.utils._process_win32', 'ctypes', '_ctypes', 'ctypes._endian', 'ctypes.wintypes', 'IPython.utils._process_common', 'shlex', 'IPython.utils.decorators', 'IPython.utils.data', 'IPython.utils.terminal', 'IPython.utils.sysinfo', 'IPython.utils._sysinfo', 'IPython.core.profiledir', 'IPython.paths', 'tempfile', 'IPython.utils.importstring', 'IPython.terminal', 'IPython.terminal.embed', 'IPython.core.compilerop', 'IPython.core.magic_arguments', 'IPython.core.error', 'IPython.utils.text', 'pathlib', 'IPython.core.magic', 'getopt', 'IPython.core.oinspect', 'IPython.core.page', 'IPython.core.display', 'binascii', 'mimetypes', 'IPython.lib', 'IPython.lib.security', 'getpass', 'IPython.lib.pretty', 'datetime', '_datetime', 'IPython.utils.signatures', 'IPython.utils.dir2', 'IPython.utils.wildcard', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.plugin', 'pygments.lexers.python', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.token', 'pygments.regexopt', 'pygments.unistring', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'IPython.core.inputsplitter', 'IPython.core.inputtransformer', 'IPython.core.splitinput', 'IPython.utils.tokenize2', 'IPython.core.interactiveshell', 'pickleshare', 'pickle', '_compat_pickle', '_pickle', 'IPython.core.prefilter', 'IPython.core.autocall', 'IPython.core.macro', 'IPython.core.alias', 'IPython.core.builtin_trap', 'IPython.core.events', 'backcall', 'backcall.backcall', 'IPython.core.displayhook', 'IPython.core.displaypub', 'IPython.core.extensions', 'IPython.core.formatters', 'IPython.utils.sentinel', 'IPython.core.history', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'IPython.core.logger', 'IPython.core.payload', 'IPython.core.usage', 'IPython.display', 'IPython.lib.display', 'html', 'html.entities', 'IPython.utils.io', 'IPython.utils.capture', 'IPython.utils.strdispatch', 'IPython.core.hooks', 'IPython.utils.syspathcontext', 'IPython.utils.tempdir', 'typing', 'typing.io', 'typing.re', 'IPython.utils.contexts', 'IPython.terminal.interactiveshell', 'prompt_toolkit', 'prompt_toolkit.interface', 'prompt_toolkit.application', 'prompt_toolkit.buffer', 'prompt_toolkit.auto_suggest', 'prompt_toolkit.filters', 'prompt_toolkit.filters.base', 'prompt_toolkit.utils', 'wcwidth', 'wcwidth.wcwidth', 'wcwidth.table_wide', 'wcwidth.table_zero', 'six.moves', 'prompt_toolkit.filters.cli', 'prompt_toolkit.enums', 'prompt_toolkit.key_binding', 'prompt_toolkit.key_binding.vi_state', 'prompt_toolkit.cache', 'prompt_toolkit.filters.types', 'prompt_toolkit.filters.utils', 'prompt_toolkit.clipboard', 'prompt_toolkit.clipboard.base', 'prompt_toolkit.selection', 'prompt_toolkit.clipboard.in_memory', 'prompt_toolkit.completion', 'prompt_toolkit.document', 'prompt_toolkit.history', 'prompt_toolkit.search_state', 'prompt_toolkit.validation', 'prompt_toolkit.buffer_mapping', 'prompt_toolkit.key_binding.bindings', 'prompt_toolkit.key_binding.bindings.basic', 'prompt_toolkit.keys', 'prompt_toolkit.layout', 'prompt_toolkit.layout.containers', 'prompt_toolkit.layout.controls', 'prompt_toolkit.mouse_events', 'prompt_toolkit.token', 'prompt_toolkit.layout.lexers', 'prompt_toolkit.layout.utils', 'prompt_toolkit.layout.processors', 'prompt_toolkit.reactive', 'prompt_toolkit.layout.screen', 'prompt_toolkit.layout.dimension', 'prompt_toolkit.layout.margins', 'prompt_toolkit.renderer', 'prompt_toolkit.layout.mouse_handlers', 'prompt_toolkit.output', 'prompt_toolkit.styles', 'prompt_toolkit.styles.base', 'prompt_toolkit.styles.defaults', 'prompt_toolkit.styles.from_dict', 'prompt_toolkit.styles.utils', 'prompt_toolkit.styles.from_pygments', 'pygments.style', 'pygments.styles.default', 'prompt_toolkit.key_binding.bindings.named_commands', 'prompt_toolkit.key_binding.bindings.completion', 'prompt_toolkit.key_binding.registry', 'prompt_toolkit.key_binding.input_processor', 'prompt_toolkit.key_binding.bindings.emacs', 'prompt_toolkit.key_binding.bindings.scroll', 'prompt_toolkit.key_binding.bindings.vi', 'prompt_toolkit.key_binding.digraphs', 'prompt_toolkit.key_binding.defaults', 'prompt_toolkit.eventloop', 'prompt_toolkit.eventloop.base', 'prompt_toolkit.eventloop.callbacks', 'prompt_toolkit.input', 'prompt_toolkit.terminal', 'prompt_toolkit.terminal.win32_input', 'prompt_toolkit.win32_types', 'prompt_toolkit.shortcuts', 'prompt_toolkit.layout.menus', 'prompt_toolkit.layout.prompt', 'prompt_toolkit.layout.toolbars', 'prompt_toolkit.terminal.win32_output', 'prompt_toolkit.terminal.conemu_output', 'prompt_toolkit.terminal.vt100_output', 'array', 'prompt_toolkit.key_binding.manager', 'IPython.terminal.debugger', 'IPython.core.completer', 'unicodedata', 'IPython.core.latex_symbols', 'IPython.utils.generics', 'simplegeneric', 'jedi', 'jedi.api', 'parso', 'parso.parser', 'parso.tree', 'parso._compatibility', 'parso.pgen2', 'parso.pgen2.parse', 'parso.python', 'parso.python.tokenize', 'parso.python.token', 'parso.utils', 'parso.grammar', 'parso.pgen2.pgen', 'parso.pgen2.grammar', 'parso.python.diff', 'difflib', 'parso.python.parser', 'parso.python.tree', 'parso.python.prefix', 'parso.cache', 'gc', 'socket', '_socket', 'selectors', 'select', 'parso.python.errors', 'parso.normalizer', 'parso.python.pep8', 'jedi._compatibility', 'queue', 'jedi.parser_utils', 'jedi.debug', 'jedi.settings', 'jedi.cache', 'jedi.api.classes', 'jedi.evaluate', 'jedi.evaluate.utils', 'jedi.evaluate.imports', 'jedi.evaluate.sys_path', 'jedi.evaluate.cache', 'jedi.evaluate.base_context', 'jedi.common', 'jedi.common.context', 'jedi.evaluate.helpers', 'jedi.evaluate.compiled', 'jedi.evaluate.compiled.context', 'jedi.evaluate.filters', 'jedi.evaluate.flow_analysis', 'jedi.evaluate.recursion', 'jedi.evaluate.lazy_context', 'jedi.evaluate.compiled.access', 'jedi.evaluate.compiled.getattr_static', 'jedi.evaluate.compiled.fake', 'jedi.common.utils', 'jedi.evaluate.analysis', 'jedi.evaluate.context', 'jedi.evaluate.context.module', 'jedi.evaluate.context.klass', 'jedi.evaluate.context.function', 'jedi.evaluate.docstrings', 'jedi.evaluate.pep0484', 'jedi.evaluate.arguments', 'jedi.evaluate.context.iterable', 'jedi.evaluate.param', 'jedi.evaluate.context.asynchronous', 'jedi.evaluate.parser_cache', 'jedi.evaluate.context.instance', 'jedi.evaluate.syntax_tree', 'jedi.evaluate.finder', 'jedi.api.keywords', 'pydoc_data', 'pydoc_data.topics', 'jedi.api.interpreter', 'jedi.evaluate.compiled.mixed', 'jedi.api.helpers', 'jedi.api.completion', 'jedi.api.environment', 'filecmp', 'distutils', 'distutils.spawn', 'distutils.errors', 'distutils.debug', 'distutils.log', 'jedi.evaluate.compiled.subprocess', 'jedi.evaluate.compiled.subprocess.functions', 'jedi.api.exceptions', 'jedi.api.project', 'jedi.evaluate.usages', 'IPython.terminal.ptutils', 'IPython.terminal.shortcuts', 'IPython.lib.clipboard', 'IPython.terminal.magics', 'IPython.terminal.pt_inputhooks', 'IPython.terminal.prompts', 'IPython.terminal.ipapp', 'IPython.core.magics', 'IPython.core.magics.auto', 'IPython.core.magics.basic', 'IPython.core.magics.code', 'IPython.core.magics.config', 'IPython.core.magics.display', 'IPython.core.magics.execution', 'timeit', 'cProfile', '_lsprof', 'profile', 'optparse', 'pstats', 'IPython.utils.module_paths', 'imp', 'IPython.utils.timing', 'IPython.core.magics.extension', 'IPython.core.magics.history', 'IPython.core.magics.logging', 'IPython.core.magics.namespace', 'IPython.core.magics.osm', 'IPython.core.magics.pylab', 'IPython.core.pylabtools', 'IPython.core.magics.script', 'IPython.lib.backgroundjobs', 'IPython.core.shellapp', 'IPython.extensions', 'IPython.extensions.storemagic', 'IPython.utils.frame', 'jupyter_client', 'jupyter_client._version', 'jupyter_client.connect', 'zmq', 'zmq.libzmq', 'zmq.backend', 'zmq.backend.select', 'zmq.backend.cython', 'cython_runtime', 'zmq.backend.cython.constants', '_cython_0_27_3', 'zmq.backend.cython.error', 'zmq.utils', 'zmq.utils.strtypes', 'zmq.backend.cython.message', 'zmq.error', 'zmq.backend.cython.context', 'zmq.backend.cython.socket', 'zmq.backend.cython.utils', 'zmq.backend.cython._poll', 'zmq.backend.cython._version', 'zmq.backend.cython._device', 'zmq.sugar', 'zmq.sugar.constants', 'zmq.utils.constant_names', 'zmq.sugar.context', 'zmq.sugar.attrsettr', 'zmq.sugar.socket', 'zmq.sugar.poll', 'zmq.sugar.frame', 'zmq.sugar.tracker', 'zmq.sugar.version', 'zmq.sugar.stopwatch', 'jupyter_client.localinterfaces', 'jupyter_core', 'jupyter_core.version', 'jupyter_core.paths', 'jupyter_client.launcher', 'traitlets.log', 'jupyter_client.client', 'jupyter_client.channels', 'jupyter_client.channelsabc', 'jupyter_client.clientabc', 'jupyter_client.manager', 'jupyter_client.kernelspec', 'jupyter_client.managerabc', 'jupyter_client.blocking', 'jupyter_client.blocking.client', 'jupyter_client.blocking.channels', 'jupyter_client.multikernelmanager', 'uuid', 'ctypes.util', 'ipykernel.kernelapp', 'tornado', 'tornado.ioloop', 'numbers', 'tornado.concurrent', 'tornado.log', 'logging.handlers', 'tornado.escape', 'tornado.util', 'tornado.speedups', 'colorama', 'colorama.initialise', 'colorama.ansitowin32', 'colorama.ansi', 'colorama.winterm', 'colorama.win32', 'tornado.stack_context', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'concurrent.futures.process', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', '__mp_main__', 'multiprocessing.connection', '_multiprocessing', 'multiprocessing.util', 'concurrent.futures.thread', 'asyncio', '_overlapped', 'asyncio.base_events', 'asyncio.compat', 'asyncio.coroutines', 'asyncio.events', 'asyncio.base_futures', 'asyncio.log', 'asyncio.futures', 'asyncio.base_tasks', '_asyncio', 'asyncio.tasks', 'asyncio.locks', 'asyncio.protocols', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.transports', 'asyncio.windows_events', 'asyncio.base_subprocess', 'asyncio.proactor_events', 'asyncio.constants', 'asyncio.sslproto', 'ssl', 'ipaddress', '_ssl', 'base64', 'asyncio.selector_events', 'asyncio.windows_utils', 'tornado.platform', 'tornado.platform.auto', 'tornado.platform.common', 'tornado.platform.interface', 'tornado.platform.windows', 'zmq.eventloop', 'zmq.eventloop.ioloop', 'tornado.platform.asyncio', 'tornado.gen', 'zmq.eventloop.zmqstream', 'zmq.utils.jsonapi', 'ipykernel.iostream', 'jupyter_client.session', 'hmac', 'jupyter_client.jsonutil', 'dateutil', 'dateutil._version', 'dateutil.parser', 'dateutil.parser._parser', 'calendar', 'decimal', '_decimal', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.tz.win', 'dateutil.parser.isoparser', '_strptime', 'jupyter_client.adapter', 'ipykernel.heartbeat', 'ipykernel.ipkernel', 'IPython.utils.tokenutil', 'ipykernel.comm', 'ipykernel.comm.manager', 'ipykernel.comm.comm', 'ipykernel.kernelbase', 'ipykernel.jsonutil', 'ipykernel.zmqshell', 'IPython.core.payloadpage', 'ipykernel.displayhook', 'ipykernel.parentpoller', 'faulthandler', 'ipykernel.datapub', 'ipykernel.serialize', 'ipykernel.pickleutil', 'ipykernel.codeutil', 'IPython.core.completerlib', 'storemagic', 'parsers', 'parsers.utils', 'utils', 'utils.os_utils', 'vqa_logger', 'parsers.VQA18', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._import_tools', 'numpy.add_newdocs', 'numpy.lib', 'numpy.lib.info', 'numpy.lib.type_check', 'numpy.core', 'numpy.core.info', 'numpy.core.multiarray', 'numpy.core.umath', 'numpy.core._internal', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'numpy.core.numerictypes', 'numpy.core.numeric', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.shape_base', 'numpy.core.einsumfunc', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing.decorators', 'numpy.testing.nose_tools', 'numpy.testing.nose_tools.decorators', 'numpy.testing.nose_tools.utils', 'numpy.lib.utils', 'numpy.testing.nosetester', 'numpy.testing.nose_tools.nosetester', 'numpy.testing.utils', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.lib.function_base', 'numpy.lib.twodim_base', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.lib.stride_tricks', 'numpy.lib.mixins', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.scimath', 'numpy.lib.polynomial', 'numpy.linalg', 'numpy.linalg.info', 'numpy.linalg.linalg', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy._distributor_init', 'numpy.fft', 'numpy.fft.info', 'numpy.fft.fftpack', 'numpy.fft.fftpack_lite', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random.info', 'mtrand', 'numpy.random.mtrand', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'pandas.compat', 'distutils.version', 'http', 'http.client', 'email', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'email._parseaddr', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'pandas.compat.chainmap', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslib', 'pandas._libs.tslibs', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.timezones', 'dateutil.zoneinfo', 'tarfile', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.fields', 'pandas._libs.hashtable', 'pandas._libs.lib', 'pandas._libs.interval', 'pandas.core', 'pandas.core.config_init', 'pandas.core.config', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.printing', 'pandas.core.dtypes', 'pandas.core.dtypes.inference', 'pandas.io.formats.console', 'pandas.io.formats.terminal', 'pandas.core.api', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.common', 'pandas._libs.algos', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.missing', 'pandas.core.common', 'pandas.api', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.core.dtypes.concat', 'pandas.errors', 'pandas.core.categorical', 'pandas.core.accessor', 'pandas.core.base', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.util._validators', 'pandas.core.nanops', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.core.groupby', 'pandas.core.index', 'pandas.core.indexes', 'pandas.core.indexes.api', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.indexes.frozen', 'pandas.core.sorting', 'pandas.core.ops', 'pandas.core.strings', 'pandas.core.indexes.category', 'pandas.core.indexes.multi', 'pandas.core.indexes.interval', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.numeric', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.tseries.offsets', 'pandas.core.tools', 'pandas.core.tools.datetimes', 'pandas._libs.tslibs.strptime', 'dateutil.easter', 'pandas._libs.tslibs.frequencies', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.timedeltas', 'pandas._libs.period', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.range', 'pandas.core.indexes.period', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas.core.internals', 'pandas.core.sparse', 'pandas.core.sparse.array', 'pandas._libs.sparse', 'pandas.io.formats.format', 'pandas.io.common', 'csv', '_csv', 'mmap', 'urllib.request', 'urllib.error', 'urllib.response', 'nturl2path', 'pandas.io.formats.common', 'pandas.core.series', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._misc', 'pandas.plotting._style', 'pandas.plotting._compat', 'pandas.plotting._tools', 'pandas.plotting._core', 'pandas.plotting._converter', 'matplotlib', 'distutils.sysconfig', 'matplotlib.cbook', 'gzip', 'matplotlib.cbook.deprecation', 'matplotlib.cbook._backports', 'matplotlib.compat', 'matplotlib.compat.subprocess', 'matplotlib.rcsetup', 'matplotlib.testing', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'six.moves.urllib', 'six.moves.urllib.request', 'matplotlib._version']\n"
     ]
    }
   ],
   "source": [
    "from parsers.VQA18 import Vqa18Base\n",
    "df_train = Vqa18Base.get_instance(train_data.processed_xls).data            \n",
    "df_val = Vqa18Base.get_instance(validation_data.processed_xls).data\n",
    "# df_train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:07:55,12 pythonVQA DEBUG ## Creating meta data ('C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\Cognitive-LUIS-Windows-master\\Sample\\VQA.Python\\data\\my_data_prepro.json')\n",
      "09:07:55,154 pythonVQA DEBUG ## Creating meta data ('C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\Cognitive-LUIS-Windows-master\\Sample\\VQA.Python\\data\\my_data_prepro.json')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Creating training meta -----\n",
      "column question had 3317 unique words\n",
      "column answer had 3255 unique words\n",
      "total unique words: 3578\n",
      "\n",
      "----- Creating validation meta -----\n",
      "column question had 399 unique words\n",
      "column answer had 669 unique words\n",
      "total unique words: 881\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Creating training meta -----\")\n",
    "meta_train = create_meta(data_prepo_meta, df_train)\n",
    "\n",
    "print(\"\\n----- Creating validation meta -----\")\n",
    "meta_validation = create_meta(data_prepo_meta, df_val)\n",
    "\n",
    "# meta_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The functions the gets the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "def prepare_embeddings(metadata):\n",
    "    embedding_filename = embedding_matrix_filename\n",
    "    num_words = len(metadata['ix_to_word'].keys())\n",
    "    dim_embedding = embedding_dim\n",
    "\n",
    "\n",
    "\n",
    "    logger.debug(\"Embedding Data...\")\n",
    "    # texts = df['question']\n",
    "\n",
    "    embeddings_index = {}\n",
    "    i = -1\n",
    "    line = \"NO DATA\"\n",
    "\n",
    "\n",
    "    glove_line_count = File.file_len(glove_path, encoding=\"utf8\")\n",
    "    def process_line(i, line):\n",
    "        print_progress(i, glove_line_count)\n",
    "        try:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "            print_progress(i+1, glove_line_count)\n",
    "        except Exception as ex:\n",
    "            logger.error(\n",
    "                \"An error occurred while working on glove file [line {0}]:\\n\"\n",
    "                \"Line text:\\t{1}\\nGlove path:\\t{2}\\n\"\n",
    "                \"{3}\".format(\n",
    "                    i, line, glove_path, ex))\n",
    "            raise\n",
    "\n",
    "\n",
    "    # with open(glove_path, 'r') as glove_file:\n",
    "    with VerboseTimer(\"Embedding\"):\n",
    "        with open(glove_path, 'r', encoding=\"utf8\") as glove_file:\n",
    "            [process_line(i=i, line=line)for i, line in enumerate(glove_file)]\n",
    "\n",
    "\n",
    "\n",
    "    embedding_matrix = np.zeros((num_words, dim_embedding))\n",
    "    word_index = metadata['ix_to_word']\n",
    "\n",
    "    with VerboseTimer(\"Creating matrix\"):\n",
    "        embedding_tupl = ((word, i, embeddings_index.get(word)) for word, i in word_index.items())\n",
    "        embedded_with_values = [(word, i, embedding_vector) for word, i, embedding_vector in embedding_tupl if embedding_vector is not None]\n",
    "\n",
    "        for word, i, embedding_vector in embedded_with_values:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "    e = {tpl[0] for tpl in embedded_with_values}\n",
    "    w = set(word_index.keys())\n",
    "    words_with_no_embedding = w-e\n",
    "    rnd = random.sample(words_with_no_embedding , 5)\n",
    "    logger.debug(\"{0} words did not have embedding. e.g.:\\n{1}\".format(len(words_with_no_embedding),rnd))\n",
    "\n",
    "    with VerboseTimer(\"Dumping matrix\"):\n",
    "        with h5py.File(embedding_filename, 'w') as f:\n",
    "            f.create_dataset('embedding_matrix', data=embedding_matrix)\n",
    "\n",
    "    return embedding_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the embedding already exists, save yourself the time and just load it.  \n",
    "Otherwise - calculate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:07:59,93 pythonVQA DEBUG ## Embedding Data already exists. Loading...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(embedding_matrix_filename):\n",
    "    logger.debug(\"Embedding Data already exists. Loading...\")\n",
    "    with h5py.File(embedding_matrix_filename) as f:\n",
    "        embedding_train = np.array(f['embedding_matrix'])    \n",
    "else:\n",
    "    logger.debug(\"Calculating Embedding...\")\n",
    "    embedding_train = prepare_embeddings(meta_train)\n",
    "    \n",
    "embedding_matrix = embedding_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44398999,  0.12817   , -0.25246999, ..., -0.20043001,\n",
       "        -0.082191  , -0.06255   ],\n",
       "       [ 0.08561   ,  0.077471  , -1.01680005, ..., -0.30044001,\n",
       "         0.012508  ,  0.24875   ],\n",
       "       [-0.16277   ,  0.033858  , -0.39416999, ...,  0.20255999,\n",
       "        -0.17546999, -0.30397999],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.21359   ,  0.85279   ,  0.48688999, ..., -0.19047   ,\n",
       "        -0.058526  , -0.49094   ],\n",
       "       [ 0.72328001, -0.1178    , -0.022166  , ...,  0.49592999,\n",
       "        -0.16937999, -0.58451003]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets wrap it with related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EmbeddingData(Embedding length:3578, Embedding dim: 300, seq length: 26, meta length: 2)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vqa_flow.data_structures import EmbeddingData\n",
    "def get_embedding_data(embedding_matrix, meta_data):    \n",
    "    dim = embedding_dim\n",
    "    s_length = seq_length    \n",
    "    return EmbeddingData(embedding_matrix=embedding_matrix,embedding_dim=dim, seq_length=s_length, meta_data=meta_data)\n",
    "\n",
    "embedding_train = get_embedding_data(embedding_matrix, meta_train)\n",
    "str(embedding_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define how to build the word-to vector branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_2_vec_model(embedding_matrix, num_words, embedding_dim, seq_length, input_tensor):\n",
    "        # notes:\n",
    "        # num works: scalar represents size of original corpus\n",
    "        # embedding_dim : dim reduction. every input string will be encoded in a binary fashion using a vector of this length\n",
    "        # embedding_matrix (AKA embedding_initializers): represents a pre trained network\n",
    "\n",
    "        LSTM_UNITS = 512\n",
    "        DENSE_UNITS = 1024\n",
    "        DENSE_ACTIVATION = 'relu'\n",
    "\n",
    "\n",
    "        logger.debug(\"Creating Embedding model\")\n",
    "        x = Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length=seq_length,trainable=False)(input_tensor)\n",
    "        x = LSTM(units=LSTM_UNITS, return_sequences=True, input_shape=(seq_length, embedding_dim))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LSTM(units=LSTM_UNITS, return_sequences=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(units=DENSE_UNITS, activation=DENSE_ACTIVATION)(x)\n",
    "        model = x\n",
    "        logger.debug(\"Done Creating Embedding model\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same manner, define how to build the image representation branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, GlobalAveragePooling2D#, Input, Dropout\n",
    "def get_image_model(base_model_weights=DEFAULT_IMAGE_WIEGHTS, out_put_dim=1024):\n",
    "    base_model_weights = base_model_weights\n",
    "\n",
    "    # base_model = VGG19(weights=base_model_weights,include_top=False)\n",
    "    base_model = VGG19(weights=base_model_weights, include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    # add a global spatial average pooling layer\n",
    "    x = GlobalAveragePooling2D(name=\"image_model_average_pool\")(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(out_put_dim, activation='relu',name=\"image_model_dense\")(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    # predictions = Dense(200, activation='softmax')(x)\n",
    "    model = x\n",
    "    \n",
    "    return base_model.input , model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, just for making sure, lets clear the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as keras_backend\n",
    "keras_backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, building the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.layers as keras_layers\n",
    "#Available merge strategies:\n",
    "# keras_layers.multiply, keras_layers.add, keras_layers.concatenate, \n",
    "# keras_layers.average, keras_layers.co, keras_layers.dot, keras_layers.maximum\n",
    "            \n",
    "merge_strategy = keras_layers.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:08:20,371 pythonVQA DEBUG ## Getting embedding (lstm model)\n",
      "09:08:20,372 pythonVQA DEBUG ## Creating Embedding model\n",
      "09:08:24,397 pythonVQA DEBUG ## Done Creating Embedding model\n",
      "09:08:24,397 pythonVQA DEBUG ## Getting image model\n",
      "09:08:25,497 pythonVQA DEBUG ## merging final model\n",
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1b3ff55a518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Model, models, Input, callbacks\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.layers import Dense, Embedding, LSTM, BatchNormalization#, GlobalAveragePooling2D, Merge, Flatten\n",
    "\n",
    "def get_vqa_model(embedding_data=None):        \n",
    "        embedding_matrix = embedding_data.embedding_matrix\n",
    "        num_words = embedding_data.num_words\n",
    "        num_classes = embedding_data.num_classes\n",
    "\n",
    "        DENSE_UNITS = 1000\n",
    "        DENSE_ACTIVATION = 'relu'\n",
    "\n",
    "        OPTIMIZER = 'rmsprop'\n",
    "        LOSS = 'categorical_crossentropy'\n",
    "        METRICS = 'accuracy'\n",
    "\n",
    "        image_model, lstm_model, fc_model = None, None, None\n",
    "        try:\n",
    "\n",
    "            lstm_input_tensor = Input(shape=(embedding_dim,), name='embedding_input')\n",
    "\n",
    "            logger.debug(\"Getting embedding (lstm model)\")\n",
    "            lstm_model = word_2_vec_model(embedding_matrix=embedding_matrix, num_words=num_words, embedding_dim=embedding_dim,\n",
    "                                               seq_length=seq_length, input_tensor=lstm_input_tensor)\n",
    "\n",
    "            logger.debug(\"Getting image model\")\n",
    "            out_put_dim = lstm_model.shape[-1].value\n",
    "            image_input_tensor, image_model = get_image_model(out_put_dim=out_put_dim)\n",
    "\n",
    "\n",
    "            logger.debug(\"merging final model\")\n",
    "            fc_tensors = merge_strategy(inputs=[image_model, lstm_model])\n",
    "            fc_tensors = BatchNormalization()(fc_tensors)\n",
    "            fc_tensors = Dense(units=DENSE_UNITS, activation=DENSE_ACTIVATION)(fc_tensors)\n",
    "            fc_tensors = BatchNormalization()(fc_tensors)\n",
    "            fc_tensors = Dense(units=num_classes, activation='softmax')(fc_tensors)\n",
    "\n",
    "            fc_model = Model(input=[lstm_input_tensor, image_input_tensor], output=fc_tensors)\n",
    "            fc_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[METRICS])\n",
    "        except Exception as ex:\n",
    "            logger.error(\"Got an error while building vqa model:\\n{0}\".format(ex))\n",
    "            models = [(image_model, 'image_model'), (lstm_model, 'lstm_model'), (fc_model, 'lstm_model')]\n",
    "            for m, name in models:\n",
    "                if m is not None:\n",
    "                    logger.error(\"######################### {0} model details: ######################### \".format(name))\n",
    "                    try:\n",
    "                        m.summary(print_fn=logger.error)\n",
    "                    except Exception as ex2:\n",
    "                        logger.warning(\"Failed to print summary for {0}:\\n{1}\".format(name, ex2))\n",
    "            raise\n",
    "\n",
    "        return fc_model\n",
    "\n",
    "model = get_vqa_model(embedding_data=embedding_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the summary of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, None, None, 2 590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, None, None, 5 2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_input (InputLayer)    (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 26, 300)      1073400     embedding_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 26, 512)      1665024     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, None, None, 5 2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 26, 512)      2048        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, None, None, 5 0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 512)          2099200     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "image_model_average_pool (Globa (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "image_model_dense (Dense)       (None, 1024)         525312      image_model_average_pool[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         525312      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2048)         0           image_model_dense[0][0]          \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2048)         8192        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         2049000     batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000)         4000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4471)         4475471     batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 32,453,391\n",
      "Trainable params: 31,371,847\n",
      "Non-trainable params: 1,081,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We better save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:08:25,680 pythonVQA DEBUG ## saving model to: 'C:\\Users\\Public\\Documents\\Data\\2018\\vqa_models\\20180608_0908_25\\vqa_model.h5'\n",
      "09:08:26,448 pythonVQA DEBUG ## model saved\n",
      "09:08:26,449 pythonVQA DEBUG ## Writing history\n",
      "09:08:26,455 pythonVQA DEBUG ## Done Writing History\n"
     ]
    }
   ],
   "source": [
    "def print_model_summary_to_file(fn, model):\n",
    "    # Open the file\n",
    "    with open(fn,'w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "        \n",
    "\n",
    "ts = get_time_stamp()\n",
    "\n",
    "now_folder = os.path.abspath('{0}\\\\{1}\\\\'.format(vqa_models_folder, ts))\n",
    "model_fn = os.path.join(now_folder, 'vqa_model.h5')\n",
    "model_image_fn = os.path.join(now_folder, 'model_vqa.png5')\n",
    "summary_fn = os.path.join(now_folder, 'model_summary.txt')\n",
    "logger.debug(\"saving model to: '{0}'\".format(model_fn))\n",
    "\n",
    "try:\n",
    "    File.validate_dir_exists(now_folder)\n",
    "    model.save(model_fn)  # creates a HDF5 file 'my_model.h5'\n",
    "    logger.debug(\"model saved\")\n",
    "except Exception as ex:\n",
    "    logger.error(\"Failed to save model:\\n{0}\".format(ex))\n",
    "\n",
    "try:\n",
    "    logger.debug(\"Writing history\")\n",
    "    print_model_summary_to_file(summary_fn, model)\n",
    "    logger.debug(\"Done Writing History\")\n",
    "#     logger.debug(\"Plotting model\")\n",
    "#     plot_model(model, to_file=model_image_fn)\n",
    "#     logger.debug(\"Done Plotting\")\n",
    "except Exception as ex:\n",
    "    logger.warning(\"{0}\".format(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1b3ff55a518>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "keras_backend.clear_session()\n",
    "\n",
    "def get_categorial_labels(df, meta):\n",
    "    classes = df['answer']\n",
    "    class_count = len(classes)\n",
    "    classes_indices = list(meta['ix_to_ans'].keys())\n",
    "    categorial_labels = to_categorical(classes_indices, num_classes=class_count)\n",
    "\n",
    "    return categorial_labels\n",
    "\n",
    "categorial_labels_train = get_categorial_labels(df_train, meta_train)\n",
    "categorial_labels_val = get_categorial_labels(df_val, meta_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keras_backend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a821259917c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkeras_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_categorial_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras_backend' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model, to_categorical\n",
    "import cv2\n",
    "keras_backend.clear_session()\n",
    "\n",
    "def get_categorial_labels(df, meta):\n",
    "    classes = df['answer']\n",
    "    class_count = len(classes)\n",
    "    classes_indices = list(meta['ix_to_ans'].keys())\n",
    "    categorial_labels = to_categorical(classes_indices, num_classes=class_count)\n",
    "\n",
    "    return categorial_labels\n",
    "\n",
    "categorial_labels_train = get_categorial_labels(df_train, meta_train)\n",
    "categorial_labels_val = get_categorial_labels(df_val, meta_validation)\n",
    "\n",
    "\n",
    "\n",
    "image_model = get_image_model()\n",
    "def get_image(image_file_name):\n",
    "    ''' Runs the given image_file to VGG 16 model and returns the\n",
    "    weights (filters) as a 1, 4096 dimension vector '''\n",
    "    image_size = image_size_by_base_models[DEFAULT_IMAGE_WIEGHTS]\n",
    "    im = cv2.resize(cv2.imread(image_file_name), image_size)\n",
    "\n",
    "    # convert the image to RGBA\n",
    "    im = im.transpose((2, 0, 1))\n",
    "    return im\n",
    "\n",
    "\n",
    "import spacy\n",
    "vectors = ['en_core_web_lg','en_core_web_md', 'en_core_web_sm']#'en_vectors_web_lg'\n",
    "vector = vectors[2]\n",
    "print(f'using vector: {vector}')\n",
    "#\n",
    "# en_core_web_md, en_core_web_lg, en_vectors_web_lg\n",
    "# en_core_web_sm\n",
    "# 'en_glove_cc_300_1m_vectors'\n",
    "\n",
    "word_embeddings = spacy.load('en', vectors=vector)\n",
    "def get_question_features(question):\n",
    "    ''' For a given question, a unicode string, returns the time series vector\n",
    "    with each word (token) transformed into a 300 dimension representation\n",
    "    calculated using Glove Vector '''\n",
    "    tokens = word_embeddings(question)\n",
    "    question_tensor = np.zeros((1, len(tokens), 384))\n",
    "\n",
    "    for j, token in enumerate(tokens):\n",
    "        # print(len(token.vector))\n",
    "        question_tensor[0,j,:] = token.vector\n",
    "\n",
    "    return question_tensor\n",
    "\n",
    "\n",
    "image_name_question = df_train[['image_name', 'question']].copy()\n",
    "image_name_question['image_name'] = image_name_question['image_name']\\\n",
    "                                    .apply(lambda q: q if q.lower().endswith('.jpg') else q+'.jpg')\n",
    "\n",
    "image_name_question['path'] =  image_name_question['image_name']\\\n",
    "                                .apply(lambda name:os.path.join(train_data.images_path, name))\n",
    "\n",
    "existing_files = [os.path.join(train_data.images_path, fn) for fn in os.listdir(train_data.images_path)]\n",
    "image_name_question = image_name_question.loc[image_name_question['path'].isin(existing_files)]\n",
    "\n",
    "image_name_question['image'] = image_name_question['path']\\\n",
    "                                .apply(lambda im_path: get_image(im_path))\n",
    "\n",
    "image_name_question['question_embedding'] = image_name_question['question']\\\n",
    "                                            .apply(lambda q: get_question_features(q))\n",
    "\n",
    "\n",
    "image_name_question.to_hdf('model_input.h5', key='df')    \n",
    "# store = HDFStore('model_input.h5')\n",
    "\n",
    "# store['df'] = image_name_question  # save it\n",
    "# store['df']  # load it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# images_path = [(fn, os.path.join(train_data.images_path, fn)) for fn in os.listdir(train_data.images_path) if fn.endswith('jpg')]\n",
    "# image_names = [t[0] for t in images_path]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_train['image_path'] = df_train\n",
    "# questions = 1\n",
    "# image_file_name = images_path[0]\n",
    "# images = np.array([get_image(image_fn) for image_fn in images_path])\n",
    "\n",
    "# image_model[-1].predict(images)\n",
    "\n",
    "\n",
    "# get_image(image_file_name)\n",
    "# image_features = [get_image(image_fn) for image_fn in images_path]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python conda_env",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
