{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG all words are Classes (Trainable params: 1,070,916). 'categorical_crossentropy', 'sigmoid' .With f1_score, recall_score, precision_score + accuracy metrics\n",
    "model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180830_1046_30\\\\vqa_model_CATEGORIAL.h5'\n",
    "strategy_str = 'CATEGORIAL'\n",
    "## VGG all words are Classes (Trainable params: 1,070,916). 'categorical_crossentropy', 'softmax' .With f1_score, recall_score, precision_score + accuracy metrics\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180829_0830_48\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "## VGG all words are Classes (Trainable params: 1,070,916) With f1_score, recall_score, precision_score + accuracy metrics\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180828_2149_37\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "## VGG all words are Classes (Trainable params: 1,070,916)\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180827_1502_41\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "## VGG 2 Classes (Trainable params: 165,762)\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180814_2035_20\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "## VGG 4 Classes\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180730_0648_46\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "# model_location = 'C:\\\\Users\\\\Public\\\\Documents\\\\Data\\\\2018\\\\vqa_models\\\\20180728_2248_02\\\\vqa_model_CATEGORIAL.h5'\n",
    "# strategy_str = 'CATEGORIAL'\n",
    "\n",
    "# ## Resnet 50: \n",
    "# trained_model_location = 'C:\\Users\\Public\\Documents\\Data\\2018\\vqa_models\\20180730_0524_48\\vqa_model_ClassifyStrategies.CATEGORIAL_trained.h5'\n",
    "# loss: 0.1248 - acc: 0.9570 - val_loss: 2.7968 - val_acc: 0.5420\n",
    "# Training Model: 12:22:54.619203                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\conda_env\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "from vqa_logger import logger \n",
    "from enum import Enum\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as keras_backend, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "import IPython\n",
    "from common.functions import get_highlited_function_code, get_features, _concat_row, sentences_to_hot_vector, hot_vector_to_words\n",
    "from common.constatns import data_location, vqa_models_folder, vqa_specs_location #train_data, validation_data, \n",
    "from common.utils import VerboseTimer\n",
    "from common.settings import classify_strategy\n",
    "from common.classes import ClassifyStrategies, EarlyStoppingByAccuracy\n",
    "from common.model_utils import save_model\n",
    "from common.os_utils import File\n",
    "from evaluate.statistical import f1_score, recall_score, precision_score\n",
    "from evaluate.WbssEvaluator import wbss_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: 0:00:02.658235\n"
     ]
    }
   ],
   "source": [
    "with VerboseTimer(\"Loading Model\"):\n",
    "    model = load_model(model_location, custom_objects= {'f1_score': f1_score, 'recall_score':recall_score, 'precision_score':precision_score})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.debug(f\"Loading the data from {data_location}\")\n",
    "with VerboseTimer(\"Loading Data\"):\n",
    "    with HDFStore(data_location) as store:\n",
    "        df_data = store['data']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_specs = File.load_pickle(vqa_specs_location)\n",
    "meta_data_location = vqa_specs.meta_data_location\n",
    "\n",
    "\n",
    "df_meta_answers = pd.read_hdf(meta_data_location,'answers')\n",
    "df_meta_words = pd.read_hdf(meta_data_location,'words')\n",
    "df_meta_imaging_devices = pd.read_hdf(meta_data_location,'imaging_devices')\n",
    "df_meta_answers.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"df_data Shape: {df_data.shape}\")\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packaging the data to be in expected input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It makes no sense to train on imageing devices we don't know thier lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTN: \n",
    "cols_to_remove = ['both', 'unknown']\n",
    "def filter_out_unknown_devices(df):\n",
    "    valid_devices = df_meta_imaging_devices.imaging_device.values\n",
    "    return df[df.imaging_device.isin(valid_devices)]\n",
    "\n",
    "\n",
    "df_data_orig = df_data \n",
    "df_data = filter_out_unknown_devices(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_data[df_data.group == 'train'].copy().reset_index()\n",
    "data_val = df_data[df_data.group == 'validation'].copy().reset_index()\n",
    "\n",
    "# print(f'groups:\\n{df_data.group.drop_duplicates()}')\n",
    "# print(len(df_data))\n",
    "# data_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The functions for getting the features & labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import get_features, _concat_row\n",
    "code_get_features = get_highlited_function_code( get_features, remove_comments=True)\n",
    "code_concat = get_highlited_function_code(_concat_row, remove_comments=True)\n",
    "IPython.display.display(code_get_features)\n",
    "IPython.display.display(code_concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining how to get NLP labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nlp_labels():\n",
    "    labels =  _concat_row(df, 'answer_embedding')\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining how to get Categorial fetaures / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_train\n",
    "\n",
    "class_df = df_meta_words\n",
    "class_count = len(class_df)\n",
    "# class_df\n",
    "\n",
    "classes_indices_df = [class_df.loc[class_df.word.isin(ans.lower().split())] for ans in  df.answer]\n",
    "classes_indices = [list(d.index) for d in classes_indices_df]\n",
    "\n",
    "idx_sample = 9\n",
    "print(df.answer[idx_sample])\n",
    "classes_indices[idx_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will transform the sentences into vector and back using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = get_highlited_function_code(sentences_to_hot_vector,remove_comments=False)\n",
    "IPython.display.display(code)    \n",
    "\n",
    "code = get_highlited_function_code(hot_vector_to_words,remove_comments=False)\n",
    "IPython.display.display(code)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check it looks sane by inversing the binarizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_meta_words.word\n",
    "sentences =  data_train.answer\n",
    "\n",
    "arr_one_hot_vector = sentences_to_hot_vector(sentences, words)\n",
    "categorial_labels = arr_one_hot_vector\n",
    "\n",
    "idx = 100\n",
    "answer =  data_train.answer.loc[idx]\n",
    "print(f'The sentence:\\n{answer}')\n",
    "\n",
    "one_hot_vector = arr_one_hot_vector[idx]\n",
    "label_words = hot_vector_to_words(one_hot_vector, words)\n",
    "print('\\n\\nThe highlighed labels:')\n",
    "label_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classify_strategy == ClassifyStrategies.CATEGORIAL:        \n",
    "    get_labels = partial(sentences_to_hot_vector, words_df=df_meta_words.word)            \n",
    "    \n",
    "# elif classify_strategy == ClassifyStrategies.NLP:   \n",
    "#     get_labels = get_nlp_features_and_labels    \n",
    "\n",
    "# Note: The shape of answer (for a single recored ) is (number of words, 384)\n",
    "else:\n",
    "    raise Exception(f'Unfamilier strategy: {strat}')\n",
    "print(f'classify stratagy: {classify_strategy}')\n",
    "\n",
    "with VerboseTimer('Getting train features'):\n",
    "    features_t = get_features(data_train)   \n",
    "with VerboseTimer('Getting train labels'):\n",
    "    labels_t = get_labels(data_train.answer)        \n",
    "    \n",
    "with VerboseTimer('Getting train features'):\n",
    "    features_val = get_features(data_val)\n",
    "with VerboseTimer('Getting validation labels'):\n",
    "    labels_val = get_labels(data_val.answer)\n",
    "\n",
    "# len(features_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = (features_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Expectedt shape: {model.input_shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual training shape:{features_t[0].shape, features_t[1].shape}')\n",
    "print(f'Train Labels shape:{labels_t.shape}')\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(f'Actual Validation shape:{features_val[0].shape, features_val[1].shape}')\n",
    "print(f'Validation Labels shape:{labels_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.gpu_utils import test_gpu\n",
    "# test_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "# EPOCHS=25\n",
    "# BATCH_SIZE = 20\n",
    "\n",
    "EPOCHS= 1\n",
    "BATCH_SIZE = 75\n",
    "\n",
    "# train_features = image_name_question\n",
    "# validation_input = (validation_features, categorial_validation_labels)\n",
    "\n",
    "## construct the image generator for data augmentation\n",
    "# aug = image.ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "#                                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "#                                horizontal_flip=True, fill_mode=\"nearest\")\n",
    "# train_generator = aug.flow(train_features, categorial_train_labels)\n",
    "\n",
    "# stop_callback = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1,mode='auto')\n",
    "history = None\n",
    "try:\n",
    "#     history = model.fit_generator(train_generator,\n",
    "#                                   validation_data=validation_input,\n",
    "#                                   steps_per_epoch=len(train_features) // self.batch_size,\n",
    "#                                   epochs=self.epochs,\n",
    "#                                   verbose=1,\n",
    "#                                   callbacks=[stop_callback],\n",
    "#                                   class_weight=class_weight\n",
    "#                                   )\n",
    "    # verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import keras.backend.tensorflow_backend as ktf\n",
    "\n",
    "\n",
    "    def get_session(gpu_fraction=0.333):\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction,allow_growth=True)\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "    stop_callback = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.02, patience=0, verbose=1,mode='auto')\n",
    "    acc_early_stop = EarlyStoppingByAccuracy(monitor='accuracy', value=0.98, verbose=1)\n",
    "    \n",
    "    tensor_log_dir = os.path.abspath(os.path.join('.','tensor_board_logd'))\n",
    "    File.validate_dir_exists(tensor_log_dir )\n",
    "    tensor_board_callback = callbacks.TensorBoard(log_dir=tensor_log_dir )\n",
    "    callbacks = [stop_callback, acc_early_stop, tensor_board_callback ]  \n",
    "\n",
    "    with VerboseTimer(\"Training Model\"):\n",
    "#         with get_session() as sess:\n",
    "#             ktf.set_session(sess)\n",
    "#             sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "        history = model.fit(features_t,labels_t,\n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data=validation_input,\n",
    "                            shuffle=True,\n",
    "                            callbacks=callbacks)\n",
    "#             sess.close()\n",
    "            \n",
    "except Exception as ex:\n",
    "    logger.error(\"Got an error training model: {0}\".format(ex))\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with VerboseTimer(\"Saving trained Model\"):\n",
    "    name_suffix = f'{classify_strategy}_trained'\n",
    "    model_fn, summary_fn, fn_image, fn_history = save_model(model, vqa_models_folder, name_suffix=name_suffix, history=history)\n",
    "\n",
    "msg = f\"Summary: {summary_fn}\\n\"\n",
    "msg += f\"Image: {fn_image}\\n\"\n",
    "msg += f'History: {fn_history or \"NONE\"}\\n' \n",
    "location_message = f\"model_location = '{model_fn}'\"\n",
    "\n",
    "\n",
    "\n",
    "print(msg)\n",
    "print(location_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (location_message.replace('\\\\','\\\\\\\\'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_env",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
