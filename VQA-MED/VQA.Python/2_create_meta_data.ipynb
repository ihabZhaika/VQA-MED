{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.constatns import data_location, vqa_specs_location, fn_meta\n",
    "from common.settings import embedding_dim, seq_length\n",
    "from common.classes import VqaSpecs\n",
    "from common.utils import VerboseTimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and creating meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data itself, Note the only things required in dataframe are:\n",
    "1. image_name\n",
    "2. question\n",
    "3. answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\model_input.h5\n",
      "Loading Data: 0:00:17.857326\n",
      "Data length: 5913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>group</th>\n",
       "      <th>path</th>\n",
       "      <th>tumor</th>\n",
       "      <th>hematoma</th>\n",
       "      <th>brain</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>neck</th>\n",
       "      <th>liver</th>\n",
       "      <th>imaging_device</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>question_embedding</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rjv03401.jpg</td>\n",
       "      <td>what does MRI show?</td>\n",
       "      <td>tumor at tail pancreas</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>mri</td>\n",
       "      <td>[[3.8335671424865723, 0.9851416349411011, 0.60...</td>\n",
       "      <td>[[-2.1287951469421387, 2.4069643020629883, 0.9...</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAN-14-313-g002.jpg</td>\n",
       "      <td>where does axial seCTion MRI abdomen show hypo...</td>\n",
       "      <td>distal pancreas</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>mri</td>\n",
       "      <td>[[0.9880439043045044, 0.907943844795227, -1.30...</td>\n",
       "      <td>[[0.329662561416626, 1.4127026796340942, -3.38...</td>\n",
       "      <td>[[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_name                                           question  \\\n",
       "0          rjv03401.jpg                                what does MRI show?   \n",
       "1  AIAN-14-313-g002.jpg  where does axial seCTion MRI abdomen show hypo...   \n",
       "\n",
       "                   answer  group  \\\n",
       "0  tumor at tail pancreas  train   \n",
       "1         distal pancreas  train   \n",
       "\n",
       "                                                path  tumor  hematoma  brain  \\\n",
       "0  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...   True     False  False   \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2018\\VQAMed2018...  False     False  False   \n",
       "\n",
       "   abdomen   neck  liver imaging_device  \\\n",
       "0    False  False  False            mri   \n",
       "1     True  False  False            mri   \n",
       "\n",
       "                                    answer_embedding  \\\n",
       "0  [[3.8335671424865723, 0.9851416349411011, 0.60...   \n",
       "1  [[0.9880439043045044, 0.907943844795227, -1.30...   \n",
       "\n",
       "                                  question_embedding  \\\n",
       "0  [[-2.1287951469421387, 2.4069643020629883, 0.9...   \n",
       "1  [[0.329662561416626, 1.4127026796340942, -3.38...   \n",
       "\n",
       "                                               image  \n",
       "0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "1  [[[9, 9, 9], [9, 9, 9], [10, 10, 10], [9, 9, 9...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'loading from:\\n{data_location}')\n",
    "with VerboseTimer(\"Loading Data\"):\n",
    "    with HDFStore(data_location) as store:\n",
    "         df_data = store['data']\n",
    "        \n",
    "df_data = df_data[df_data.group.isin(['train','validation'])]\n",
    "print(f'Data length: {len(df_data)}')        \n",
    "df_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ct' 'mri' 'unknown']\n",
      "['ct' 'mri']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = df_data[df_data.imaging_device.isin(['ct','mri'])]\n",
    "print(np.unique(df_data.imaging_device))\n",
    "print(np.unique(d.imaging_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use this function for creating meta data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqa_logger import logger \n",
    "import itertools\n",
    "import string\n",
    "from common.os_utils import File #This is a simplehelper file of mine...\n",
    "\n",
    "def create_meta(df, hdf_output_location):\n",
    "        \n",
    "        print(f\"Dataframe had {len(df)} rows\")\n",
    "        english_stopwords = set(stopwords.words('english'))\n",
    "        def get_unique_words(col):           \n",
    "            single_string = \" \".join(df[col])\n",
    "            exclude = set(string.punctuation)\n",
    "            s_no_panctuation = ''.join(ch.lower() for ch in single_string if ch not in exclude)\n",
    "            unique_words = set(s_no_panctuation.split(\" \")).difference({'',' '})            \n",
    "            unique_words = unique_words.difference(english_stopwords)\n",
    "            print(\"column {0} had {1} unique words\".format(col,len(unique_words)))\n",
    "            return unique_words\n",
    "\n",
    "        cols = ['question', 'answer']\n",
    "        df_unique_words = set(itertools.chain.from_iterable([get_unique_words(col) for col in cols]))\n",
    "        df_unique_answers = set([ans.lower() for ans in df['answer']])        \n",
    "        \n",
    "        df_unique_imaging_devices = set(df['imaging_device'])\n",
    "        unknown_devices = ['both', 'unknown']\n",
    "        df_unique_imaging_devices = [v for v in df_unique_imaging_devices if v not in unknown_devices]\n",
    "        \n",
    "\n",
    "        words = sorted(list(df_unique_words), key=lambda w: (len(w),w))\n",
    "        words = [w for w in words if \n",
    "                 w in ['ct', 'mri'] \n",
    "                 or len(w) >=3 \n",
    "                 and not w[0].isdigit() ]\n",
    "        \n",
    "        metadata_dict = {}       \n",
    "        metadata_dict['words'] = {'word': words}            \n",
    "        metadata_dict['answers'] = {'answer':list(df_unique_answers)}            \n",
    "        metadata_dict['imaging_devices'] = {'imaging_device': df_unique_imaging_devices}\n",
    "            \n",
    "\n",
    "        try:\n",
    "            os.remove(hdf_output_location)\n",
    "        except OSError:\n",
    "            pass\n",
    "        \n",
    "        for name, dictionary in metadata_dict.items():\n",
    "            df_curr = pd.DataFrame(dictionary,dtype=str)\n",
    "            df_curr.to_hdf(hdf_output_location, name, format='table')\n",
    "            \n",
    "\n",
    "        \n",
    "        with HDFStore(hdf_output_location) as metadata_store:           \n",
    "            print(\"Meta number of unique answers: {0}\".format(len(metadata_store['answers'])))\n",
    "            print(\"Meta number of unique words: {0}\".format(len(metadata_store['words'])))\n",
    "\n",
    "#         df_ix_to_word = pd.DataFrame.from_dict(metadata['ix_to_word'])\n",
    "#         light.to_hdf(data_location, 'light', mode='w', data_columns=['image_name', 'imaging_device', 'path'], format='table')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Creating meta -----\n",
      "Dataframe had 5913 rows\n",
      "column question had 3223 unique words\n",
      "column answer had 3200 unique words\n",
      "Meta number of unique answers: 4740\n",
      "Meta number of unique words: 3389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word\n",
       "0   ct\n",
       "1  abd\n",
       "2  acl\n",
       "3  aga\n",
       "4  age"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----- Creating meta -----\")\n",
    "meta_data = create_meta(df_data, fn_meta)\n",
    "\n",
    "with HDFStore(fn_meta) as metadata_store:           \n",
    "    df_words = metadata_store['words']\n",
    "    df_answers = metadata_store['answers']\n",
    "    df_imaging_device = metadata_store['imaging_devices']\n",
    "    \n",
    "df_words.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data, so later on we don't need to compute it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VqaSpecs(embedding_dim=384, seq_length=26, data_location='C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\model_input.h5', meta_data_location='C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\meta_data.h5')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vqa_specs(meta_location):    \n",
    "    dim = embedding_dim\n",
    "    s_length = seq_length    \n",
    "    return VqaSpecs(embedding_dim=dim, \n",
    "                    seq_length=s_length, \n",
    "                    data_location=os.path.abspath(data_location),\n",
    "                    meta_data_location=os.path.abspath(meta_location))\n",
    "\n",
    "vqa_specs = get_vqa_specs(fn_meta)\n",
    "\n",
    "# Show waht we got...\n",
    "vqa_specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:28][DEBUG] VQA Specs saved to:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\vqa_specs.pkl\n"
     ]
    }
   ],
   "source": [
    "File.dump_pickle(vqa_specs, vqa_specs_location)\n",
    "logger.debug(f\"VQA Specs saved to:\\n{vqa_specs_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VqaSpecs(embedding_dim=384, seq_length=26, data_location='C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\model_input.h5', meta_data_location='C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\meta_data.h5')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vqa_specs = File.load_pickle(vqa_specs_location)\n",
    "loaded_vqa_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vqa_specs_location = 'C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\vqa_specs.pkl'\n"
     ]
    }
   ],
   "source": [
    "print (f\"vqa_specs_location = '{vqa_specs_location}'\".replace('\\\\','\\\\\\\\'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_env",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
