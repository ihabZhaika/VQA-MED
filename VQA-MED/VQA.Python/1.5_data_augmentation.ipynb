{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "import pyarrow\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import logging\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.utils import VerboseTimer\n",
    "from common.functions import get_highlighted_function_code, generate_image_augmentations,  get_image\n",
    "from common.os_utils import File\n",
    "from common.settings import data_access\n",
    "import vqa_logger \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\model_input.parquet\n",
      "[2019-02-05 21:32:05][DEBUG] Loading Data: 0:00:10.463825\n",
      "[2019-02-05 21:32:07][DEBUG] Converting to pandas: 0:00:02.232098\n"
     ]
    }
   ],
   "source": [
    "df_data = data_access.load_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 14792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_name</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>path</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>processed_answer</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>locations</th>\n",
       "      <th>imaging_device</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>question_embedding</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ct</td>\n",
       "      <td>[-0.946086049079895, 0.675370454788208, 1.3840...</td>\n",
       "      <td>[-2.1590447425842285, 3.4943666458129883, 0.19...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>synpic43984.jpg</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>no</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>[0.029011979699134827, 1.9719411134719849, 1.5...</td>\n",
       "      <td>[1.099464774131775, 0.1577463150024414, -2.948...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       image_name                      question                answer  \\\n",
       "0      0  synpic41148.jpg   what kind of image is this?  cta - ct angiography   \n",
       "1      1  synpic43984.jpg  is this a t1 weighted image?                    no   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "             processed_question      processed_answer diagnosis locations  \\\n",
       "0   what kind of image is this?  cta - ct angiography                       \n",
       "1  is this a t1 weighted image?                    no                       \n",
       "\n",
       "  imaging_device                                   answer_embedding  \\\n",
       "0             ct  [-0.946086049079895, 0.675370454788208, 1.3840...   \n",
       "1        unknown  [0.029011979699134827, 1.9719411134719849, 1.5...   \n",
       "\n",
       "                                  question_embedding  group  \n",
       "0  [-2.1590447425842285, 3.4943666458129883, 0.19...  train  \n",
       "1  [1.099464774131775, 0.1577463150024414, -2.948...  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data[df_data.group.isin(['train','validation'])]\n",
    "print(f'Data length: {len(df_data)}')        \n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             train\n",
       "12792    validation\n",
       "Name: group, dtype: category\n",
       "Categories (2, object): [train, validation]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.group.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the augmaentation we will use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.highlight .hll { background-color: #ffffcc }\n",
       ".highlight  { background: #f8f8f8; }\n",
       ".highlight .c { color: #408080; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #FF0000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".highlight .go { color: #888888 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #7D9029 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #A0A000 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">generate_image_augmentations</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">output_dir</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">rotation_range</span><span class=\"o\">=</span><span class=\"mi\">15</span><span class=\"p\">,</span>  <span class=\"c1\"># Units: degrees</span>\n",
       "                                 <span class=\"n\">width_shift_range</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">height_shift_range</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">shear_range</span><span class=\"o\">=</span><span class=\"mf\">0.</span><span class=\"p\">,</span>  <span class=\"c1\"># Units: degrees</span>\n",
       "                                 <span class=\"n\">zoom_range</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">fill_mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;nearest&#39;</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">augmentation_count</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n",
       "    <span class=\"kn\">from</span> <span class=\"nn\">keras.preprocessing.image</span> <span class=\"kn\">import</span> <span class=\"n\">ImageDataGenerator</span><span class=\"p\">,</span> <span class=\"n\">img_to_array</span><span class=\"p\">,</span> <span class=\"n\">load_img</span>  <span class=\"c1\"># ,array_to_img</span>\n",
       "\n",
       "    <span class=\"n\">datagen</span> <span class=\"o\">=</span> <span class=\"n\">ImageDataGenerator</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">rotation_range</span><span class=\"o\">=</span><span class=\"n\">rotation_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">width_shift_range</span><span class=\"o\">=</span><span class=\"n\">width_shift_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">height_shift_range</span><span class=\"o\">=</span><span class=\"n\">height_shift_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">shear_range</span><span class=\"o\">=</span><span class=\"n\">shear_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">zoom_range</span><span class=\"o\">=</span><span class=\"n\">zoom_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">horizontal_flip</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">vertical_flip</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">fill_mode</span><span class=\"o\">=</span><span class=\"n\">fill_mode</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">load_img</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a PIL image</span>\n",
       "    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">img_to_array</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a Numpy array with shape (3, X, Y)</span>\n",
       "    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,)</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a Numpy array with shape (1, 3, X, Y)</span>\n",
       "\n",
       "    <span class=\"c1\"># the .flow() command below generates batches of randomly transformed images</span>\n",
       "    <span class=\"c1\"># and saves the results to the `preview/` directory</span>\n",
       "    <span class=\"n\">ext</span> <span class=\"o\">=</span> <span class=\"n\">image_path</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
       "    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
       "    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"n\">datagen</span><span class=\"o\">.</span><span class=\"n\">flow</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">save_to_dir</span><span class=\"o\">=</span><span class=\"n\">output_dir</span><span class=\"p\">,</span> <span class=\"n\">save_format</span><span class=\"o\">=</span><span class=\"n\">ext</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"n\">augmentation_count</span><span class=\"p\">:</span>\n",
       "            <span class=\"k\">break</span>  <span class=\"c1\"># otherwise the generator would loop indefinitely</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code = get_highlighted_function_code(generate_image_augmentations,remove_comments=False)\n",
    "IPython.display.display(code)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "Generating augmentations for 0 images\n"
     ]
    }
   ],
   "source": [
    "df_train = df_data[df_data.group == 'train']\n",
    "\n",
    "image_paths = df_train.path.drop_duplicates()\n",
    "print(len(image_paths))\n",
    "\n",
    "def get_file_info(fn):\n",
    "        image_folder, full_file_name = os.path.split(fn)\n",
    "        file_name, ext = full_file_name.split('.')[-2:]        \n",
    "        output_dir = os.path.join(image_folder,'augmentations',full_file_name+'\\\\')\n",
    "        return (fn, file_name, ext, output_dir)\n",
    "\n",
    "images_info = [get_file_info(p) for p in image_paths]        \n",
    "non_existing_paths = [(fn, file_name, ext, output_dir) for (fn, file_name, ext, output_dir) in images_info if not os.path.isdir(output_dir)]\n",
    "non_existing_paths = [(i, fn, file_name, ext, output_dir) for i, (fn, file_name, ext, output_dir) in enumerate(non_existing_paths)]\n",
    "\n",
    "\n",
    "print(f'Generating augmentations for {len(non_existing_paths)} images')\n",
    "\n",
    "\n",
    "def augments_single_image(tpl_data)  :\n",
    "    try:       \n",
    "        (i, curr_image_path, file_name, ext, output_dir) = tpl_data\n",
    "        msg = (f'Augmenting ({i+1}/{len(non_existing_paths)})\\t\"{file_name}\" -> {output_dir}')  \n",
    "        if i %100 == 0:\n",
    "            print(msg)\n",
    "        File.validate_dir_exists(output_dir)\n",
    "        generate_image_augmentations(curr_image_path, output_dir)\n",
    "        res = 1\n",
    "    except Exception as e: \n",
    "        msg = str(e)\n",
    "        res = 0\n",
    "    return (res,msg)\n",
    "\n",
    "\n",
    "try:\n",
    "    # for tpl_data in non_existing_paths:\n",
    "         #augments_single_image(tpl_data)\n",
    "    pool = Pool(processes=8)\n",
    "    inputs = non_existing_paths\n",
    "    pool_res = pool.map(augments_single_image, inputs)\n",
    "    pool.terminate()\n",
    "\n",
    "except Exception as ex:\n",
    "    print(f'Error:\\n{str(ex)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: 0\n",
      "\n",
      "\n",
      "failes: 0\n"
     ]
    }
   ],
   "source": [
    "failes = [tpl[1] for tpl in pool_res if tpl[0]==0]\n",
    "successes = [tpl[1] for tpl in pool_res if tpl[0]==1]\n",
    "\n",
    "\n",
    "f_summary = '\\n'.join(failes[:5])\n",
    "s_summary = '\\n'.join(successes[:5])\n",
    "summary = f'success: {len(successes)}\\n{s_summary}\\n\\nfailes: {len(failes)}\\n{f_summary}'.strip()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3200/3200 [01:14<00:00, 42.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-04 21:54:08][DEBUG] Collecting augmented rows: 0:01:14.636945\n"
     ]
    }
   ],
   "source": [
    "# a = images_info[:1]\n",
    "a = images_info\n",
    "aug_dict = {image_path:output_dir for (image_path, file_name, ext, output_dir) in a}\n",
    "\n",
    "curr_idx = df_train.tail(1).index[0] +1\n",
    "\n",
    "df_augments = df_train.copy()\n",
    "df_augments['augmentation'] = 0\n",
    "df_augments['idx'] = 0\n",
    "\n",
    "print(len(df_augments))\n",
    "new_rows = []\n",
    "with VerboseTimer(\"Collecting augmented rows\"):\n",
    "    pbar = tqdm(aug_dict.items())\n",
    "    for image_path, output_dir in pbar:\n",
    "        #print(image_path)\n",
    "        image_rows = df_augments[df_augments.path == image_path]\n",
    "        for i_row, row in image_rows.iterrows():\n",
    "            #print(i_row)\n",
    "            augment_files = [os.path.join(output_dir, fn) for fn in sorted(os.listdir(output_dir))]\n",
    "\n",
    "            for i_augment, augment_path in enumerate(augment_files):\n",
    "                r = row.copy()\n",
    "                r.path = augment_path            \n",
    "#                 r.image = get_image(augment_path)\n",
    "                r.augmentation = i_augment + 1 \n",
    "                r.idx = curr_idx\n",
    "                curr_idx+=1\n",
    "                r.reset_index()\n",
    "                new_rows.append(r)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-04 21:54:13][DEBUG] Creating rows dataframe: 0:00:04.531613\n",
      "76748\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>group</th>\n",
       "      <th>idx</th>\n",
       "      <th>image_name</th>\n",
       "      <th>imaging_device</th>\n",
       "      <th>index</th>\n",
       "      <th>locations</th>\n",
       "      <th>path</th>\n",
       "      <th>processed_answer</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>question</th>\n",
       "      <th>question_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>[-0.946086049079895, 0.675370454788208, 1.3840...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>[-2.1590447425842285, 3.4943666458129883, 0.19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 answer                                   answer_embedding  \\\n",
       "0  cta - ct angiography  [-0.946086049079895, 0.675370454788208, 1.3840...   \n",
       "\n",
       "   augmentation diagnosis  group  idx       image_name imaging_device  index  \\\n",
       "0           NaN            train  NaN  synpic41148.jpg             ct      0   \n",
       "\n",
       "  locations                                               path  \\\n",
       "0            C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "       processed_answer           processed_question  \\\n",
       "0  cta - ct angiography  what kind of image is this?   \n",
       "\n",
       "                      question  \\\n",
       "0  what kind of image is this?   \n",
       "\n",
       "                                  question_embedding  \n",
       "0  [-2.1590447425842285, 3.4943666458129883, 0.19...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with VerboseTimer(\"Creating rows dataframe\"):\n",
    "    df_augmented_rows = pd.DataFrame(new_rows)\n",
    "    \n",
    "df = pd.concat([df_train, df_augmented_rows])    \n",
    "print(len(df))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving a meaningful index across dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['augmentation', 'idx'], ascending=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_df = len(df)\n",
    "idxs = range(0, len_df)\n",
    "len_idx = len(set(idxs))\n",
    "assert  len_idx== len_df , f'length of indexes ({len_idx}) did not match length of dataframe ({len_df})'\n",
    "df.idx = idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>group</th>\n",
       "      <th>idx</th>\n",
       "      <th>image_name</th>\n",
       "      <th>imaging_device</th>\n",
       "      <th>index</th>\n",
       "      <th>locations</th>\n",
       "      <th>path</th>\n",
       "      <th>processed_answer</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>question</th>\n",
       "      <th>question_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>[-0.946086049079895, 0.675370454788208, 1.3840...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>[-2.1590447425842285, 3.4943666458129883, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>axial</td>\n",
       "      <td>[-1.3220698833465576, -0.9305600523948669, 0.8...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>3200</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>axial</td>\n",
       "      <td>which plane is this image taken?</td>\n",
       "      <td>which plane is this image taken?</td>\n",
       "      <td>[-2.426004648208618, 4.558772087097168, 0.1516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>yes</td>\n",
       "      <td>[-2.3747644424438477, 1.0431363582611084, 1.62...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>76746</td>\n",
       "      <td>synpic48036.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>12790</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>yes</td>\n",
       "      <td>is ct normal?</td>\n",
       "      <td>is the ct scan normal?</td>\n",
       "      <td>[0.7937809228897095, 0.42329514026641846, -3.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>no</td>\n",
       "      <td>[0.029011979699134827, 1.9719411134719849, 1.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>76747</td>\n",
       "      <td>synpic54897.jpg</td>\n",
       "      <td>mr</td>\n",
       "      <td>12791</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>no</td>\n",
       "      <td>is there an abnormality in the mr?</td>\n",
       "      <td>is there an abnormality in the mri?</td>\n",
       "      <td>[1.5513315200805664, -0.19218707084655762, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     answer  \\\n",
       "0      cta - ct angiography   \n",
       "3200                  axial   \n",
       "12790                   yes   \n",
       "12791                    no   \n",
       "\n",
       "                                        answer_embedding  augmentation  \\\n",
       "0      [-0.946086049079895, 0.675370454788208, 1.3840...           1.0   \n",
       "3200   [-1.3220698833465576, -0.9305600523948669, 0.8...           1.0   \n",
       "12790  [-2.3747644424438477, 1.0431363582611084, 1.62...           NaN   \n",
       "12791  [0.029011979699134827, 1.9719411134719849, 1.5...           NaN   \n",
       "\n",
       "      diagnosis  group    idx       image_name imaging_device  index  \\\n",
       "0                train      0  synpic41148.jpg             ct      0   \n",
       "3200             train      1  synpic41148.jpg             ct   3200   \n",
       "12790            train  76746  synpic48036.jpg             ct  12790   \n",
       "12791            train  76747  synpic54897.jpg             mr  12791   \n",
       "\n",
       "      locations                                               path  \\\n",
       "0                C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "3200             C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "12790            C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "12791            C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "           processed_answer                  processed_question  \\\n",
       "0      cta - ct angiography         what kind of image is this?   \n",
       "3200                  axial    which plane is this image taken?   \n",
       "12790                   yes                       is ct normal?   \n",
       "12791                    no  is there an abnormality in the mr?   \n",
       "\n",
       "                                  question  \\\n",
       "0              what kind of image is this?   \n",
       "3200      which plane is this image taken?   \n",
       "12790               is the ct scan normal?   \n",
       "12791  is there an abnormality in the mri?   \n",
       "\n",
       "                                      question_embedding  \n",
       "0      [-2.1590447425842285, 3.4943666458129883, 0.19...  \n",
       "3200   [-2.426004648208618, 4.558772087097168, 0.1516...  \n",
       "12790  [0.7937809228897095, 0.42329514026641846, -3.6...  \n",
       "12791  [1.5513315200805664, -0.19218707084655762, -1....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0,1,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\model_input.parquet'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       augmentation    idx\n",
       "0               1.0      0\n",
       "3200            1.0      1\n",
       "12790           NaN  76746\n",
       "12791           NaN  76747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # df.head(1)\n",
    "# # len(new_rows)\n",
    "# new_rows[1].augmentation\n",
    "# df.columns\n",
    "# aug_keys = df.augmentation.drop_duplicates().values\n",
    "\n",
    "# aug_keys\n",
    "df[['augmentation','idx']].iloc[[0,1,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "aug_keys = [int(i) if not np.isnan(i) else 0 for i in df.augmentation.drop_duplicates().values]\n",
    "set(aug_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\augmentation_index.h5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  with HDFStore(data_location) as store:\n",
    "#         k = store.keys()\n",
    "# k        \n",
    "data_location\n",
    "augmentation_index = 'C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\augmentation_index.h5'\n",
    "augmentation_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_embedding</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>group</th>\n",
       "      <th>idx</th>\n",
       "      <th>image_name</th>\n",
       "      <th>imaging_device</th>\n",
       "      <th>index</th>\n",
       "      <th>locations</th>\n",
       "      <th>path</th>\n",
       "      <th>processed_answer</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>question</th>\n",
       "      <th>question_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>[-0.946086049079895, 0.675370454788208, 1.3840...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>[-2.1590447425842285, 3.4943666458129883, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>axial</td>\n",
       "      <td>[-1.3220698833465576, -0.9305600523948669, 0.8...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>3200</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>axial</td>\n",
       "      <td>which plane is this image taken?</td>\n",
       "      <td>which plane is this image taken?</td>\n",
       "      <td>[-2.426004648208618, 4.558772087097168, 0.1516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>lung, mediastinum, pleura</td>\n",
       "      <td>[-0.2881927192211151, 1.420225977897644, 2.803...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lung</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>6400</td>\n",
       "      <td>lung, mediastinum, pleura</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>lung, mediastinum, pleura</td>\n",
       "      <td>which organ is captured by this ct?</td>\n",
       "      <td>which organ is captured by this ct scan?</td>\n",
       "      <td>[-2.0855326652526855, 4.293310642242432, 0.579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9600</th>\n",
       "      <td>cryptococcal pneumonia in an immunocompetent host</td>\n",
       "      <td>[-1.6821398735046387, 0.3354760706424713, -1.6...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>synpic41148.jpg</td>\n",
       "      <td>ct</td>\n",
       "      <td>9600</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>cryptococcal pneumonia in an immunocompetent host</td>\n",
       "      <td>what is abnormal ct?</td>\n",
       "      <td>what is abnormal in the ct scan?</td>\n",
       "      <td>[-2.741878032684326, 1.224818229675293, -0.289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>[0.029011979699134827, 1.9719411134719849, 1.5...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>synpic43984.jpg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>no</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>[1.099464774131775, 0.1577463150024414, -2.948...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 answer  \\\n",
       "0                                  cta - ct angiography   \n",
       "3200                                              axial   \n",
       "6400                          lung, mediastinum, pleura   \n",
       "9600  cryptococcal pneumonia in an immunocompetent host   \n",
       "1                                                    no   \n",
       "\n",
       "                                       answer_embedding  augmentation  \\\n",
       "0     [-0.946086049079895, 0.675370454788208, 1.3840...           1.0   \n",
       "3200  [-1.3220698833465576, -0.9305600523948669, 0.8...           1.0   \n",
       "6400  [-0.2881927192211151, 1.420225977897644, 2.803...           1.0   \n",
       "9600  [-1.6821398735046387, 0.3354760706424713, -1.6...           1.0   \n",
       "1     [0.029011979699134827, 1.9719411134719849, 1.5...           1.0   \n",
       "\n",
       "     diagnosis  group  idx       image_name imaging_device  index  \\\n",
       "0               train    0  synpic41148.jpg             ct      0   \n",
       "3200            train    1  synpic41148.jpg             ct   3200   \n",
       "6400      lung  train    2  synpic41148.jpg             ct   6400   \n",
       "9600            train    3  synpic41148.jpg             ct   9600   \n",
       "1               train    4  synpic43984.jpg        unknown      1   \n",
       "\n",
       "                      locations  \\\n",
       "0                                 \n",
       "3200                              \n",
       "6400  lung, mediastinum, pleura   \n",
       "9600                              \n",
       "1                                 \n",
       "\n",
       "                                                   path  \\\n",
       "0     C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "3200  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "6400  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "9600  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "1     C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "                                       processed_answer  \\\n",
       "0                                  cta - ct angiography   \n",
       "3200                                              axial   \n",
       "6400                          lung, mediastinum, pleura   \n",
       "9600  cryptococcal pneumonia in an immunocompetent host   \n",
       "1                                                    no   \n",
       "\n",
       "                       processed_question  \\\n",
       "0             what kind of image is this?   \n",
       "3200     which plane is this image taken?   \n",
       "6400  which organ is captured by this ct?   \n",
       "9600                 what is abnormal ct?   \n",
       "1            is this a t1 weighted image?   \n",
       "\n",
       "                                      question  \\\n",
       "0                  what kind of image is this?   \n",
       "3200          which plane is this image taken?   \n",
       "6400  which organ is captured by this ct scan?   \n",
       "9600          what is abnormal in the ct scan?   \n",
       "1                 is this a t1 weighted image?   \n",
       "\n",
       "                                     question_embedding  \n",
       "0     [-2.1590447425842285, 3.4943666458129883, 0.19...  \n",
       "3200  [-2.426004648208618, 4.558772087097168, 0.1516...  \n",
       "6400  [-2.0855326652526855, 4.293310642242432, 0.579...  \n",
       "9600  [-2.741878032684326, 1.224818229675293, -0.289...  \n",
       "1     [1.099464774131775, 0.1577463150024414, -2.948...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: save as parquet. \n",
    "#### partition by augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]c:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3267: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['answer', 'answer_embedding', 'diagnosis', 'group', 'image_name', 'imaging_device', 'locations', 'path', 'processed_answer', 'processed_question', 'question', 'question_embedding']]\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-04 21:54:35][DEBUG] Storing dataframe '1': 0:00:22.259087\n",
      "[2019-02-04 21:54:35][DEBUG] Storing 6 dataframes: 0:00:22.447768\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f846c797f3e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mindex_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'store_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maugmentation_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mindex_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'store_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstore_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mstore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstore_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, key, value, format, append, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"io.hdf.default_format\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'fixed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_to_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[1;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[1;31m# write the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_table\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, obj, **kwargs)\u001b[0m\n\u001b[0;32m   2928\u001b[0m             \u001b[1;31m# I have no idea why, but writing values before items fixed #2299\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m             \u001b[0mblk_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2930\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block%d_values'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2931\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block%d_items'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(self, key, value, items)\u001b[0m\n\u001b[0;32m   2696\u001b[0m             vlarr = self._handle.create_vlarray(self.group, key,\n\u001b[0;32m   2697\u001b[0m                                                 _tables().ObjectAtom())\n\u001b[1;32m-> 2698\u001b[1;33m             \u001b[0mvlarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2699\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2700\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mempty_array\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\vqa\\lib\\site-packages\\tables\\vlarray.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mnparr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnobjects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables\\hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.VLArray._append\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "index_dict = defaultdict(lambda:[])\n",
    "\n",
    "with VerboseTimer(f\"Storing {len(aug_keys)} dataframes\"):\n",
    "    with HDFStore(augmentation_index) as store:\n",
    "        pbar = tqdm(aug_keys)\n",
    "        for aug_key in pbar:\n",
    "            with VerboseTimer(f\"Storing dataframe '{aug_key}'\"):\n",
    "                data = df[df.augmentation == aug_key]\n",
    "\n",
    "                store_key = f'augmentation_{aug_key}'\n",
    "                idxs = data.idx.values                                \n",
    "                index_dict['idx'].extend(idxs)        \n",
    "                \n",
    "                paths = data.path.values                \n",
    "                index_dict['paths'].extend(paths)                \n",
    "                \n",
    "                index_dict['image_path'].extend(paths)\n",
    "                index_dict['augmentation_key'].extend([aug_key]*len(paths))\n",
    "                index_dict['store_path'].extend([augmentation_index]*len(paths))\n",
    "                index_dict['store_key'].extend([store_key]*len(paths))\n",
    "                store[store_key] = data\n",
    "                \n",
    "        index=pd.DataFrame(index_dict) \n",
    "        store['index'] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(augmentation_index) as store:\n",
    "    loaded_index = store['index']\n",
    "\n",
    "print(f'image_path: {loaded_index.image_path[0]}')    \n",
    "print(f'store_path: {loaded_index.store_path[0]}')    \n",
    "print(f'augmentation_key: {loaded_index.augmentation_key[0]}')    \n",
    "  \n",
    "loaded_index.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(augmentation_index) as store:\n",
    "    print(list(store.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(augmentation_index) as store:\n",
    "    augmentation_1 = store['augmentation_1']\n",
    "    augmentation_5 = store['augmentation_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = min(augmentation_1.idx),max(augmentation_1.idx)\n",
    "v5 = min(augmentation_5.idx),max(augmentation_5.idx)\n",
    "\n",
    "\n",
    "print(v5)\n",
    "print(v1)\n",
    "len(augmentation_1)\n",
    "augmentation_1.head(5).idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_5.tail(5).idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
